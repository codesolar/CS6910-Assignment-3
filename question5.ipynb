{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"'''\ninstalling wandb and indic package\n'''\n!pip install wandb\n!pip install indic-nlp-library","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-21T13:57:29.019874Z","iopub.execute_input":"2023-05-21T13:57:29.020240Z","iopub.status.idle":"2023-05-21T13:57:51.606503Z","shell.execute_reply.started":"2023-05-21T13:57:29.020209Z","shell.execute_reply":"2023-05-21T13:57:51.605237Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.20.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.4)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.28.2)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: indic-nlp-library in /opt/conda/lib/python3.10/site-packages (0.92)\nRequirement already satisfied: morfessor in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library) (2.0.6)\nRequirement already satisfied: sphinx-argparse in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library) (0.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library) (1.23.5)\nRequirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library) (0.2.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from indic-nlp-library) (1.5.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->indic-nlp-library) (2023.3)\nRequirement already satisfied: sphinx>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx-argparse->indic-nlp-library) (7.0.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->indic-nlp-library) (1.16.0)\nRequirement already satisfied: sphinxcontrib-qthelp in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\nRequirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.12.1)\nRequirement already satisfied: Pygments>=2.13 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.15.0)\nRequirement already satisfied: alabaster<0.8,>=0.7 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.13)\nRequirement already satisfied: imagesize>=1.3 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\nRequirement already satisfied: sphinxcontrib-jsmath in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\nRequirement already satisfied: docutils<0.21,>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.19)\nRequirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.28.2)\nRequirement already satisfied: packaging>=21.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (21.3)\nRequirement already satisfied: sphinxcontrib-applehelp in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.4)\nRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\nRequirement already satisfied: snowballstemmer>=2.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\nRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.1.2)\nRequirement already satisfied: sphinxcontrib-devhelp in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\nRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"'''\nall important libraries are called\n'''\nfrom indicnlp.langinfo import *\nlang = 'hi'\nimport wandb\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.datasets import mnist, fashion_mnist\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport shutil\nimport torch.nn.functional as F\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:57:54.324778Z","iopub.execute_input":"2023-05-21T13:57:54.325154Z","iopub.status.idle":"2023-05-21T13:57:54.332849Z","shell.execute_reply.started":"2023-05-21T13:57:54.325120Z","shell.execute_reply":"2023-05-21T13:57:54.331957Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"'''\ndevice variable is set\n'''\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:57:55.823885Z","iopub.execute_input":"2023-05-21T13:57:55.824244Z","iopub.status.idle":"2023-05-21T13:57:55.828961Z","shell.execute_reply.started":"2023-05-21T13:57:55.824209Z","shell.execute_reply":"2023-05-21T13:57:55.828076Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"'''\ntrain path , valid path , test path are written\n'''\ntrain_path = \"/kaggle/input/dataset/aksharantar_sampled/hin/hin_train.csv\"\nvalid_path = \"/kaggle/input/dataset/aksharantar_sampled/hin/hin_valid.csv\"\ntest_path = \"/kaggle/input/dataset/aksharantar_sampled/hin/hin_test.csv\"","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:57:56.926282Z","iopub.execute_input":"2023-05-21T13:57:56.927150Z","iopub.status.idle":"2023-05-21T13:57:56.932374Z","shell.execute_reply.started":"2023-05-21T13:57:56.927106Z","shell.execute_reply":"2023-05-21T13:57:56.931459Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"'''\nthe train test validation set are these\n'''\ndf_train = pd.read_csv(train_path,names = ['X','y'])\ndf_valid = pd.read_csv(valid_path,names = ['X','y'])\ndf_test = pd.read_csv(test_path,names = ['X','y'])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:57:57.945812Z","iopub.execute_input":"2023-05-21T13:57:57.946529Z","iopub.status.idle":"2023-05-21T13:57:58.055786Z","shell.execute_reply.started":"2023-05-21T13:57:57.946494Z","shell.execute_reply":"2023-05-21T13:57:58.054756Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"'''\ntarget word's maxlength(Hindi) and source word's maxlength(english) are these\n'''\ntargetmaxlen = 0\nsourcemaxlen = 0\nfor word in df_train.iloc[:,1]:\n    targetmaxlen = max(targetmaxlen,len(word))\nfor word in df_train.iloc[:,0]:\n    sourcemaxlen = max(sourcemaxlen,len(word))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:57:58.976910Z","iopub.execute_input":"2023-05-21T13:57:58.977267Z","iopub.status.idle":"2023-05-21T13:57:59.040647Z","shell.execute_reply.started":"2023-05-21T13:57:58.977238Z","shell.execute_reply":"2023-05-21T13:57:59.039787Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"SOW_token = 0\nEOW_token = 1\n\n\nclass Lang:\n    def __init__(self):\n        self.char2index = {'-' : '-'}\n        self.index2char = {0: '0', 1: '1'} #'0' sow and '1' eow\n        self.n_chars = 2  # Count SOS and EOS\n\n\n    def addWord(self, word):\n        for c in word:\n            if c not in self.char2index:\n                self.char2index[c] = self.n_chars\n                self.index2char[self.n_chars] = c\n                self.n_chars += 1","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:47:15.947313Z","iopub.execute_input":"2023-05-21T14:47:15.947673Z","iopub.status.idle":"2023-05-21T14:47:15.955232Z","shell.execute_reply.started":"2023-05-21T14:47:15.947643Z","shell.execute_reply":"2023-05-21T14:47:15.954270Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"lang_input = Lang()\nlang_output = Lang()\n# li = list(df_train['X'])","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:00.989767Z","iopub.execute_input":"2023-05-21T13:58:00.990749Z","iopub.status.idle":"2023-05-21T13:58:00.996076Z","shell.execute_reply.started":"2023-05-21T13:58:00.990694Z","shell.execute_reply":"2023-05-21T13:58:00.995040Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"english_words_train = list(df_train['X'])\nfor word in english_words_train:\n    lang_input.addWord(word)\nhindi_words_train = list(df_train['y'])\nfor word in hindi_words_train:\n    lang_output.addWord(word)\n    \n    \nenglish_words_valid = list(df_valid['X'])\nfor word in english_words_valid:\n    lang_input.addWord(word)\nhindi_words_valid = list(df_valid['y'])\nfor word in hindi_words_valid:\n    lang_output.addWord(word)\n    \n    \nenglish_words_test = list(df_test['X'])\nfor word in english_words_test:\n    lang_input.addWord(word)\nhindi_words_test = list(df_test['y'])\nfor word in hindi_words_test:\n    lang_output.addWord(word)    ","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:02.449869Z","iopub.execute_input":"2023-05-21T13:58:02.450230Z","iopub.status.idle":"2023-05-21T13:58:02.598948Z","shell.execute_reply.started":"2023-05-21T13:58:02.450197Z","shell.execute_reply":"2023-05-21T13:58:02.597876Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"def indexesFromWord(lang, word):\n    li = []\n    for c in word:\n        li.append(lang.char2index[c])\n    return li\n\n\ndef tensorFromWord(lang, word):\n    indexes = indexesFromWord(lang, word)\n    indexes.append(EOW_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:03.700083Z","iopub.execute_input":"2023-05-21T13:58:03.700760Z","iopub.status.idle":"2023-05-21T13:58:03.706675Z","shell.execute_reply.started":"2023-05-21T13:58:03.700724Z","shell.execute_reply":"2023-05-21T13:58:03.705735Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"imax = 30\nfor i in range(len(english_words_train)):\n    for j in range(imax - len(english_words_train[i])):\n        english_words_train[i] = english_words_train[i] + '-'","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:47:27.933758Z","iopub.execute_input":"2023-05-21T14:47:27.934188Z","iopub.status.idle":"2023-05-21T14:47:27.975563Z","shell.execute_reply.started":"2023-05-21T14:47:27.934153Z","shell.execute_reply":"2023-05-21T14:47:27.974612Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"'''\nEncoder class is here .\nIt extends nn of pytorch \ninput_size = Vocabulary size of source language(integer)\nhidden_size = number of neurons in the hidden layer of the encoder(integer)\ndrop_out = probability of a node being dropped out(number between 0 to 1)\nnum_layers = How many layers does the encoder has , These layers are stacked, one above another(Integer)\nbatchsize = total number of word pair in a batch(Integer)\nembeddingsize = The input (source word) characters are each converted to some embedding \n                by passing through one embedding layer , this denotes the size of that \n                embedding layer(Integer)\nbidirectional = if the encoder is bidirectional or not (takes boolean True / False)\nmodelname = name of the model (can be RNN , GRU , LSTM )(str) \ninput = Batch of words or a single word\nencoder_hidden = a tuple containing ( hidden , cell ) , LSTM has cell , so I kept a cell \n                It is used when needed , hidden and cell are initialised with initHidden method\nreturns output , a tuple containing hidden and cell state\n'''\nclass EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size,drop_out,num_layers,batchsize,embeddingsize,bidirectional,modelname):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.batchsize = batchsize\n        self.drop_out = drop_out\n        self.num_layers = num_layers\n        self.embeddingsize = embeddingsize\n        self.embedding = nn.Embedding(input_size, embeddingsize)\n        self.bidirectional = bidirectional\n        self.D = 1\n        if self.bidirectional == True:\n            self.D = 2\n        self.modelname = modelname\n        if modelname == 'RNN':\n            self.model = nn.RNN(input_size = embeddingsize, hidden_size = hidden_size,num_layers = num_layers,bidirectional = self.bidirectional)\n        elif modelname == 'GRU':\n            self.model = nn.GRU(input_size = embeddingsize, hidden_size = hidden_size,num_layers = num_layers,bidirectional = self.bidirectional)\n        elif modelname == 'LSTM':\n            self.model = nn.LSTM(input_size = embeddingsize, hidden_size = hidden_size,num_layers = num_layers,bidirectional = self.bidirectional)\n\n        self.dropout = nn.Dropout(self.drop_out)\n\n    def forward(self, input, encoder_hidden):\n        embedded = self.embedding(input).view(-1,self.batchsize,self.embeddingsize)\n        maxlength = embedded.size()[0]\n        (hidden ,cell) = encoder_hidden\n        output = self.dropout(embedded)\n\n    \n        if self.modelname == 'RNN':\n            output, hidden = self.model(output, hidden)\n            cell = None\n        elif self.modelname == 'GRU':\n            output, hidden = self.model(output, hidden)\n            cell = None\n        elif self.modelname == 'LSTM':\n            output, (hidden,cell) = self.model(output, (hidden,cell))\n\n        if self.D == 2:\n            h = 0\n            o = 0\n            newoutput = torch.zeros(maxlength, self.batchsize, self.hidden_size, device = device)\n            newhidden = torch.zeros(self.num_layers, self.batchsize, self.hidden_size, device = device)\n            for i in range(0,self.D * self.num_layers,2):\n                newhidden[h, : , :] = torch.div(hidden[i, :, :].add(hidden[i + 1, :, :]),2)\n                h += 1\n            hidden = newhidden\n            for i in range(0,self.D * self.hidden_size,2):\n                newoutput[: , : ,o] = torch.div(output[: ,: ,i].add(output[: , : ,i + 1]),2)\n                o += 1\n            output = newoutput\n            if cell != None:\n                c = 0\n                newcell = torch.zeros(self.num_layers, self.batchsize, self.hidden_size, device = device)\n                for i in range(0,self.D * self.num_layers,2):\n                    newcell[c, : , :] = torch.div(cell[i, :, :].add(cell[i + 1, :, :]),2)\n                    c += 1\n                cell = newcell\n        return output, (hidden,cell)\n\n    def initHidden(self):\n        return torch.zeros(self.D * self.num_layers, self.batchsize, self.hidden_size, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:06.203667Z","iopub.execute_input":"2023-05-21T13:58:06.204018Z","iopub.status.idle":"2023-05-21T13:58:06.226752Z","shell.execute_reply.started":"2023-05-21T13:58:06.203989Z","shell.execute_reply":"2023-05-21T13:58:06.225681Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# a = torch.FloatTensor([[2,3],[4,7]])\n# s = nn.LogSoftmax(dim=1)\n# s(a)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:08.267923Z","iopub.execute_input":"2023-05-21T13:58:08.268272Z","iopub.status.idle":"2023-05-21T13:58:08.272576Z","shell.execute_reply.started":"2023-05-21T13:58:08.268244Z","shell.execute_reply":"2023-05-21T13:58:08.271575Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"'''\nDecoder class is here .\nIt extends nn of pytorch \nhidden_size = number of neurons in the hidden layer of the encoder(integer)\noutput_size = Vocabulary size of target language(integer)\ndrop_out = probability of a node being dropped out(number between 0 to 1)\nnum_layers = How many layers does the decoder has , These layers are stacked, one above another(Integer)\nbatchsize = total number of word pair in a batch(Integer)\nembeddingsize = The word (target word) characters are each converted to some embedding \n                by passing through one embedding layer , this denotes the size of that \n                embedding layer(Integer)\nmodelname = name of the model (can be RNN , GRU , LSTM )(str) \ninput = Batch of words or a single word or batch of words at a timestamp \nencoder_hidden = a tuple containing ( hidden , cell ) , LSTM has cell , so I kept a cell \n                It is used when needed , hidden and cell are initialised with initHidden method\nencoder_output = output of encoder (needed in attention implementation)\n\n\nreturns output , a tuple of hidden and cell state , attention weights (None as it is a normal decoder)\n'''\n\nclass DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size,drop_out,num_layers,batchsize,embeddingsize,modelname):\n        super(DecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.batchsize = batchsize\n        self.num_layers = num_layers\n        self.drop_out = drop_out\n        self.embeddingsize = embeddingsize\n        self.embedding = nn.Embedding(output_size, embeddingsize)\n        self.modelname = modelname\n        if modelname == 'RNN':\n            self.model = nn.RNN(embeddingsize, hidden_size,num_layers)\n        elif modelname == 'GRU':\n            self.model = nn.GRU(embeddingsize, hidden_size,num_layers)\n        elif modelname == 'LSTM':\n            self.model = nn.LSTM(embeddingsize, hidden_size,num_layers)\n\n        self.dropout = nn.Dropout(self.drop_out)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, input, encoder_hidden,encoder_output):\n        output = self.embedding(input).view(-1, self.batchsize, self.embeddingsize)\n        output = self.dropout(output)\n        output = F.relu(output)\n        (hidden, cell) = encoder_hidden\n        if self.modelname == 'RNN':\n            output, hidden = self.model(output, hidden)\n        elif self.modelname == 'GRU':\n            output, hidden = self.model(output, hidden)\n        elif self.modelname == 'LSTM':\n            output, (hidden,cell) = self.model(output, (hidden,cell))\n        \n        output = self.softmax(self.out(output[0]))#dim = [128,67] before applying softmax\n        return output, (hidden,cell),None","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:09.405877Z","iopub.execute_input":"2023-05-21T13:58:09.406254Z","iopub.status.idle":"2023-05-21T13:58:09.421124Z","shell.execute_reply.started":"2023-05-21T13:58:09.406222Z","shell.execute_reply":"2023-05-21T13:58:09.420037Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# a = torch.zeros(2,4)\n# b = torch.zeros(3,4)\n# torch.cat((a,b))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:11.081102Z","iopub.execute_input":"2023-05-21T13:58:11.081724Z","iopub.status.idle":"2023-05-21T13:58:11.086234Z","shell.execute_reply.started":"2023-05-21T13:58:11.081688Z","shell.execute_reply":"2023-05-21T13:58:11.085227Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"'''\nAttnDecoder class is here .\nIt extends nn of pytorch \nhidden_size = number of neurons in the hidden layer of the encoder(integer)\noutput_size = Vocabulary size of target language(integer)\ndrop_out = probability of a node being dropped out(number between 0 to 1)\nnum_layers = How many layers does the decoder has , These layers are stacked, one above another(Integer)\nbatchsize = total number of word pair in a batch(Integer)\nembeddingsize = The word (target word) characters are each converted to some embedding \n                by passing through one embedding layer , this denotes the size of that \n                embedding layer(Integer)\nmodelname = name of the model (can be RNN , GRU , LSTM )(str) \ninput = Batch of words or a single word or batch of words at a timestamp \nencoder_hidden = a tuple containing ( hidden , cell ) , LSTM has cell , so I kept a cell \n                It is used when needed , hidden and cell are initialised with initHidden method\nencoder_output = output of encoder (needed in attention implementation)\n\n\nreturns output , a tuple of hidden and cell state , attention weights (None as it is a normal decoder)\n'''\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size,drop_out,num_layers,batchsize,embeddingsize,modelname):\n        super(AttnDecoderRNN, self).__init__()\n        maxlength = imax + 1\n        self.hidden_size = hidden_size\n        self.batchsize = batchsize\n        self.num_layers = num_layers\n        self.drop_out = drop_out\n        self.embeddingsize = embeddingsize\n        self.embedding = nn.Embedding(output_size, embeddingsize)\n        self.modelname = modelname\n        if modelname == 'RNN':\n            self.model = nn.RNN(embeddingsize, hidden_size,num_layers)\n        elif modelname == 'GRU':\n            self.model = nn.GRU(embeddingsize, hidden_size,num_layers)\n        elif modelname == 'LSTM':\n            self.model = nn.LSTM(embeddingsize, hidden_size,num_layers)\n#         self.gru = nn.GRU(embeddingsize, hidden_size,num_layers,dropout = drop_out,bidirectional = False)\n        self.dropout = nn.Dropout(self.drop_out)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.softmax = nn.LogSoftmax(dim=1)\n        self.attn = nn.Linear(self.hidden_size + self.embeddingsize, maxlength).to(device)\n        self.attn_combine = nn.Linear(self.hidden_size + self.embeddingsize, self.embeddingsize).to(device)\n    def forward(self, input, encoder_hidden,encoder_output):\n        \n        (hidden, cell) = encoder_hidden\n        output = self.embedding(input).view(-1, self.batchsize, self.embeddingsize)\n        output = self.dropout(output)\n        cat = torch.cat((output[0], hidden[0]), 1)\n        attn_weights = F.softmax(\n            self.attn(cat), dim=1)\n        attn_applied = torch.bmm(attn_weights.unsqueeze(1),\n                                 torch.permute(encoder_output,(1,0,2)))\n\n        output = torch.cat((output[0], attn_applied.squeeze(1)), 1)\n        output = self.attn_combine(output).unsqueeze(0)\n\n        \n        output = F.relu(output)\n        if self.modelname == 'RNN':\n            output, hidden = self.model(output, hidden)\n        elif self.modelname == 'GRU':\n            output, hidden = self.model(output, hidden)\n        elif self.modelname == 'LSTM':\n            output, (hidden,cell) = self.model(output, (hidden,cell))\n        \n        output = self.softmax(self.out(output[0])) #dim = [128,67] before applying softmax\n        return output, (hidden,cell),attn_weights","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:12.314261Z","iopub.execute_input":"2023-05-21T13:58:12.314737Z","iopub.status.idle":"2023-05-21T13:58:12.340262Z","shell.execute_reply.started":"2023-05-21T13:58:12.314679Z","shell.execute_reply":"2023-05-21T13:58:12.339325Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"def indexesFromWord(lang, word):\n    li = []\n    for c in word:\n        li.append(lang.char2index[c])\n    return li\n\n\ndef tensorFromWord(lang, word):\n    indexes = indexesFromWord(lang, word)\n    indexes.append(EOW_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:13.935039Z","iopub.execute_input":"2023-05-21T13:58:13.935420Z","iopub.status.idle":"2023-05-21T13:58:13.945280Z","shell.execute_reply.started":"2023-05-21T13:58:13.935389Z","shell.execute_reply":"2023-05-21T13:58:13.944202Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"'''\nThis is train function \nAt first a teacher forcing ratio is given , it is 0.5 here\ninput_tensor = one batch of tensor of source words . They are preprocessed .\n                so , every tensor in a batch is of same size as ,  every word ends by EOW token\n                and then they are padded to reach the maximum length of source word in that batch\n\ntarget_tensor = True target tensor words corresponding to the batch of input tensor . Like \n                input tensor these are also preprocessed , They end with EOW token and then\n                they are padded to reach the maximum length of words in that batch\nencoder = encoder model instance\ndecoder = decoder model instance\nencoder_optimizer = The optimizer used for the encoder ( Can be SGD , RMSprop , Adam , NAdam)\ndecoder_optimizer = The optimizer used for the decoder ( Can be SGD , RMSprop , Adam , NAdam)\ncriterion = It means The nn module's CrossEntropyLoss instance\nbatchsize = batchsize of the model (valid for both encoder and decoder)\nIt returns the loss in that batch and also the word level accuracy in that batch\n'''\n\nteacher_forcing_ratio = 0.5\n\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batchsize):\n    hidden = encoder.initHidden()\n    cell = hidden\n    encoder_hidden = (hidden, cell)\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n    # encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n    accu = 0\n    # for ei in range(input_length):\n    #     encoder_output, encoder_hidden = encoder(\n    #         input_tensor[ei], encoder_hidden)\n    #     encoder_outputs[ei] = encoder_output[0, 0]\n    # print(input_tensor.shape)\n#     print(input_tensor)\n    encoder_output, encoder_hidden = encoder(\n            input_tensor, encoder_hidden)\n    decoder_input = torch.tensor([SOW_token] * batchsize, device=device)\n    d_hidden = torch.zeros(decoder.num_layers, decoder.batchsize, decoder.hidden_size, device = device)\n    d_cell = torch.zeros(decoder.num_layers, decoder.batchsize, decoder.hidden_size, device = device)\n    (hidden, cell) = encoder_hidden \n    if encoder.num_layers != decoder.num_layers:\n        d_hidden[:,:,:] = hidden[encoder.num_layers - 1,:,:]\n        if cell != None:\n            d_cell[:,:,:] = cell[encoder.num_layers - 1,:,:]\n        else :\n            d_cell = cell\n    else :\n        d_hidden = hidden\n        d_cell = cell\n    if d_cell == None and decoder.modelname == 'LSTM':\n        d_cell = d_hidden\n    decoder_hidden = (d_hidden , d_cell)\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n    decoder_words = []\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden ,attn_weights= decoder(\n                decoder_input, decoder_hidden,encoder_output)\n            \n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n            topv, topi = decoder_output.topk(1)\n            decoder_words.append(topi.squeeze().detach().view(1,-1))\n#             decoder_words.append([lang_output.index2char[decoder_output[i]] for i in decoder_output.size()[0])\n      \n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden,attn_weights = decoder(\n                decoder_input, decoder_hidden ,encoder_output)\n            loss += criterion(decoder_output, target_tensor[di])\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n            decoder_words.append(topi.squeeze().detach().view(1,-1))\n#             decoder_words.append([lang_output.index2char[decoder_output[i]] for i in decoder_output.size()[0])\n            \n       \n    loss.backward()\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n    accu = accuracy(decoder_words,target_tensor)\n    return loss.item() / target_length,accu","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:15.477669Z","iopub.execute_input":"2023-05-21T13:58:15.478023Z","iopub.status.idle":"2023-05-21T13:58:15.498518Z","shell.execute_reply.started":"2023-05-21T13:58:15.477992Z","shell.execute_reply":"2023-05-21T13:58:15.497519Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"'''\nencoder = encoder model instance\ndecoder = decoder model instance\nn_iters = total number of iteration of training on the whole training set or, total number of epochs\nlearning_rate = learning_rate of the optimizer model\nbatchsize = batchsize of the model\noptimizername = name of the optimizer  model used \nbeta = used in SGD for momentum hyper parameter\n\nThis function takes both source and target words , process them (changes the characters to integers) and pads \niff necessery to make each word of same length in a batch \nThen it runs total n_iters time \nIn each of them it trains each of the batch of training set and prints the training loss \n, validation loss , training accuracy , validation accuracy(after completion of an epoch)\n\n'''\ndef trainIters(encoder, decoder, n_iters, learning_rate,batchsize,optimizername,beta):\n    loss_total = 0  # Reset every print_every\n    accu_total = 0\n    if optimizername == 'Adam':\n        encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n        decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    elif optimizername == 'NAdam':\n        encoder_optimizer = optim.NAdam(encoder.parameters(), lr=learning_rate)\n        decoder_optimizer = optim.NAdam(decoder.parameters(), lr=learning_rate)\n    elif optimizername == 'RMSprop':\n        encoder_optimizer = optim.RMSprop(encoder.parameters(), lr=learning_rate)\n        decoder_optimizer = optim.RMSprop(decoder.parameters(), lr=learning_rate)\n    elif optimizername == 'SGD':\n        encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate,momentum = beta)\n        decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate,momentum = beta)\n    criterion = nn.CrossEntropyLoss()\n    \n    input_batch = []\n    output_batch = []\n    input_tensor = [tensorFromWord(lang_input,word) for word in english_words_train]\n    output_tensor = [tensorFromWord(lang_output,word) for word in hindi_words_train]\n\n    \n    \n    for i in range(0,len(english_words_train),batchsize):\n        if i + batchsize > len(english_words_train):\n            break\n        input_batch.append(nn.utils.rnn.pad_sequence(input_tensor[i:i + batchsize]).squeeze(2).to(device)) #maxlength,batchsize,1\n        output_batch.append(nn.utils.rnn.pad_sequence(output_tensor[i:i + batchsize]).squeeze(2).to(device)) #maxlength,batch\n    \n\n\n    for iter in range(1, n_iters + 1):\n        for batchnum in range(len(input_batch)):\n#             print(input_batch[batchnum])\n            loss,accu = train(input_batch[batchnum], output_batch[batchnum], encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batchsize)\n            if batchnum % 500 == 0:\n                print(loss,batchnum)\n                pass\n            loss_total += loss * batchsize\n            accu_total = accu_total + accu\n        training_loss = loss_total/len(english_words_train)\n        training_accuracy = (accu_total * 100)/(len(input_batch) * batchsize)\n        validation_loss , validation_accuracy = evaluate(encoder,decoder,df_valid,batchsize)\n        print(\"training loss after epoch no {}\".format(iter) ,training_loss)\n        print(\"training accuracy after epoch no {}\".format(iter),training_accuracy)\n        print(\"validation loss after epoch no {}\".format(iter),validation_loss)\n        print(\"validation accuracy after epoch no {}\".format(iter),validation_accuracy)\n#         wandb.log({\"training_accuracy\": training_accuracy, \"validation_accuracy\": validation_accuracy, \"training_loss\": training_loss, \"validation_loss\": validation_loss,\"Epoch\" : iter})\n\n        loss_total = 0\n        accu_total = 0","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:16.883270Z","iopub.execute_input":"2023-05-21T13:58:16.883931Z","iopub.status.idle":"2023-05-21T13:58:16.900267Z","shell.execute_reply.started":"2023-05-21T13:58:16.883898Z","shell.execute_reply":"2023-05-21T13:58:16.899204Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"encoder1 = EncoderRNN(lang_input.n_chars, 512,0.2,2,128,256,False,'LSTM').to(device)\ndecoder1 = DecoderRNN(512, lang_output.n_chars,0.2,3,128,256,'LSTM').to(device)\ndecoder2 = AttnDecoderRNN(512,lang_output.n_chars,0.2,3,128,256,'GRU').to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:38:47.637685Z","iopub.execute_input":"2023-05-21T13:38:47.638045Z","iopub.status.idle":"2023-05-21T13:38:47.778126Z","shell.execute_reply.started":"2023-05-21T13:38:47.638018Z","shell.execute_reply":"2023-05-21T13:38:47.777111Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"'''\nIt is the method which given predictedlist and actuallist returns accuracy\npredictedlist = predicted word list(target word)\nactuallist = actual word list(target word)\nIt calculates word level accuracy\n'''\n\ndef accuracy(predictedlist, actuallist):\n    accu = 0\n    N = actuallist.size()[1]\n    L = actuallist.size()[0]\n    predictedtensor = torch.zeros(L,N).to(device)\n    for i in range(L):\n        predictedtensor[i] = predictedlist[i]\n#     print(predictedtensor)\n    for i in range(N):\n        if torch.equal(predictedtensor[:,i],actuallist[:,i]) == True:\n            accu += 1\n        \n    return accu","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:21.681146Z","iopub.execute_input":"2023-05-21T13:58:21.682062Z","iopub.status.idle":"2023-05-21T13:58:21.689215Z","shell.execute_reply.started":"2023-05-21T13:58:21.682027Z","shell.execute_reply":"2023-05-21T13:58:21.688250Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"'''\nencoder = encoder model instance\ndecoder = decoder model instance\ndataset = dataset on which to evaluate the model\nbatchsize = number of words in a batch\ncalculates loss and accuracy of the model on the given dataset\n'''\n\ndef evaluate(encoder,decoder,dataset,batchsize):\n    loss_total = 0\n    accu_total = 0\n    input_batch = []\n    target_batch = []\n    encoder.eval()\n    decoder.eval()\n    criterion = nn.CrossEntropyLoss()\n    result = []\n    english_words = list(dataset['X'])\n    hindi_words = list(dataset['y'])\n    imax = 30\n    for i in range(len(english_words_valid)):\n        for j in range(imax - len(english_words_valid[i])):\n            english_words_valid[i] = english_words_valid[i] + '-'\n\n    input_tensor = [tensorFromWord(lang_input,word) for word in english_words_valid]\n    output_tensor = [tensorFromWord(lang_output,word) for word in hindi_words_valid]\n\n    \n    \n    for i in range(0,len(english_words),batchsize):\n        if i + batchsize > len(english_words):\n            break\n        input_batch.append(nn.utils.rnn.pad_sequence(input_tensor[i:i + batchsize]).squeeze(2).to(device)) #maxlength,batchsize,1\n        target_batch.append(nn.utils.rnn.pad_sequence(output_tensor[i:i + batchsize]).squeeze(2).to(device)) #maxlength,batch\n    \n    \n    loss = 0\n    for batchnum in range(len(input_batch)):\n        hidden = encoder.initHidden()\n        cell = hidden\n        encoder_hidden = (hidden, cell)\n    \n        input_length = input_batch[batchnum].size(0)\n        target_length = target_batch[batchnum].size(0)\n    \n        encoder_output, encoder_hidden = encoder(\n            input_batch[batchnum], encoder_hidden)\n        decoder_input = torch.tensor([SOW_token] * batchsize, device=device)\n\n        \n        \n        d_hidden = torch.zeros(decoder.num_layers, decoder.batchsize, decoder.hidden_size, device = device)\n        d_cell = torch.zeros(decoder.num_layers, decoder.batchsize, decoder.hidden_size, device = device)\n        (hidden, cell) = encoder_hidden \n        if encoder.num_layers != decoder.num_layers:\n            d_hidden[:,:,:] = hidden[encoder.num_layers - 1,:,:]\n            if cell != None:\n                d_cell[:,:,:] = cell[encoder.num_layers - 1,:,:]\n            else :\n                d_cell = cell\n        else :\n            d_hidden = hidden\n            d_cell = cell\n        if d_cell == None and decoder.modelname == 'LSTM':\n            d_cell = d_hidden\n        decoder_hidden = (d_hidden , d_cell)\n\n        decoder_words = []\n        res_words = []\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden,attn_weights = decoder(\n                decoder_input, decoder_hidden,encoder_output)\n            loss += criterion(decoder_output, target_batch[batchnum][di])\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n            decoder_words.append(topi.squeeze().detach().view(1,-1))\n            res_words.append(topi.squeeze().detach().view(-1,1))\n    #       decoder_words.append([lang_output.index2char[decoder_output[i]] for i in decoder_output.size()[0])\n        accu = accuracy(decoder_words,target_batch[batchnum])\n    \n        loss = loss.item() / target_length\n        loss_total += loss * batchsize\n        accu_total += accu\n\n        for i in range(batchsize):\n            resultantlist = []\n            for j in range(target_length):\n                if res_words[j][i].item() == 1:\n                    break\n                resultantlist.append(lang_output.index2char[res_words[j][i].item()])\n            result.append(resultantlist)\n    loss_total = loss_total/len(english_words)\n    accu_total = (accu_total * 100)/(len(input_batch) * batchsize)\n    print(\"loss = \", loss_total)\n    print(accu_total)\n#     finalresult = []\n#     for i in range(len(result)):\n#         finalresult.append(''.join(result[i]))\n#     print(dataset['y'][1])\n#     print(len(finalresult))\n#     correct = 0\n#     for i in range(len(finalresult)):\n#         if finalresult[i] == dataset['y'][i]:\n#             correct += 1\n#     print(correct)\n    \n#     with open('output.txt' , 'w') as fp:\n#         fp.write(\"correct output    \")\n#         fp.write(\"predicted output\\n\")\n#         fp.write(\"--------------------------------------------\\n\")\n#         for i in range(len(finalresult)):\n#             fp.write(\"--------------------------------------------\\n\")\n#             fp.write(f\"{dataset['y'][i]:<40}{finalresult[i]:<50}\")\n#             fp.write('\\n')\n#             fp.write(\"--------------------------------------------\\n\")\n# #             fp.write(\"%s\\n\"%finalresult[i])\n#     fp.close()\n    \n    \n#     vowelerror = 0\n#     consonanterror = 0\n#     vowelcorrect = 0\n#     consonantcorrect = 0\n#     for i in range(len(result)):\n#         truelist = list(dataset['y'][i])\n#         for j in range(min(len(truelist) , len(result[i]))):\n#             if is_vowel(truelist[j] , lang):\n#                 if  truelist[j] != result[i][j]:\n#                     vowelerror += 1\n#                 else:\n#                     vowelcorrect += 1\n#             elif is_consonant(truelist[j] , lang):\n#                 if  truelist[j] != result[i][j]:\n#                     consonanterror += 1\n#                 else:\n#                     consonantcorrect += 1\n#         if len(truelist) > len(result[i]):\n#             for j in range(len(result[i]) , len(truelist)):\n#                 if is_vowel(truelist[j] ,lang):\n#                     vowelerror += 1\n#                 else:\n#                     consonanterror += 1\n    \n    \n#     print(vowelerror)\n#     print(vowelcorrect)\n#     print(consonanterror)\n#     print(consonantcorrect)\n    encoder.train()\n    decoder.train()\n    return loss_total,accu_total","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:48:50.245670Z","iopub.execute_input":"2023-05-21T14:48:50.246030Z","iopub.status.idle":"2023-05-21T14:48:50.272381Z","shell.execute_reply.started":"2023-05-21T14:48:50.246000Z","shell.execute_reply":"2023-05-21T14:48:50.271246Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"sweep_configuration = {\n    'method': 'bayes',\n    'name': 'ACCURACY VS EPOCH',\n    'metric': {\n        'goal': 'maximize', \n        'name': 'validation_accuracy'\n        },\n    'parameters': {\n        'embeddingsize' : {'values' : [128,256,512]},\n        'number_of_encoder_layers' : {'values' : [2,3]},\n        'number_of_decoder_layers' : {'values' : [2,3]},\n        'hidden_size' : {'values' : [256,512,1024]},\n\n        'learning_rate': {'values':[0.0001,0.001]},\n        'beta' : {'values' : [0,0.9]},\n        'optimizer' : {'values' : ['SGD','Adam','NAdam','RMSprop']},\n        \n        'batchsize': {'values': [128,256]},\n        'bidirectional' : {'values' : [True , False]},\n        'n_iters': {'values': [20,15]},\n        'loss' : {'values' : ['cross_entropy']},\n        'encodermodelname' : {'values' : ['GRU','LSTM']},\n        'decodermodelname' : {'values' : ['GRU','LSTM']},\n        'drop_out' : {'values' : [0,0.2,0.3]}\n       }\n    }","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:25.191148Z","iopub.execute_input":"2023-05-21T13:58:25.191510Z","iopub.status.idle":"2023-05-21T13:58:25.200406Z","shell.execute_reply.started":"2023-05-21T13:58:25.191481Z","shell.execute_reply":"2023-05-21T13:58:25.199371Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"def withattention():\n    '''\n    main function which runs sweep\n    '''\n    \n    wandb.init(project = 'Assignment 3')\n    config = wandb.config\n    encoder = EncoderRNN(lang_input.n_chars,config.hidden_size ,config.drop_out,config.number_of_encoder_layers,config.batchsize,config.embeddingsize,config.bidirectional,config.encodermodelname).to(device)\n\n    attndecoder = AttnDecoderRNN(config.hidden_size,lang_output.n_chars ,config.drop_out,config.number_of_decoder_layers,config.batchsize,config.embeddingsize,config.decodermodelname).to(device)\n    run_name = \"es_{}_nenl_{}_ndel_{}_hs_{}_lr_{}_bt_{}_o_{}_bs_{}_bi_{}_n_iters_{}_loss_{}_emn_{}_dmn_{}_do_{}\".format(config.embeddingsize,config.number_of_encoder_layers,config.number_of_decoder_layers,config.hidden_size,config.learning_rate,config.beta,config.optimizer,config.batchsize,config.bidirectional,config.n_iters,config.loss,config.encodermodelname,config.decodermodelname,config.drop_out)\n    print(\"run name - \", run_name)\n    wandb.run.name = run_name\n    trainIters(encoder, attndecoder, config.n_iters, config.learning_rate, config.batchsize,config.optimizer,config.beta)\n    print(\"AFTER TRAINING - \")\n    print(\"validation accuracy\" , evaluate(encoder,attndecoder,df_valid,config.batchsize))","metadata":{"execution":{"iopub.status.busy":"2023-05-21T13:58:26.841799Z","iopub.execute_input":"2023-05-21T13:58:26.842776Z","iopub.status.idle":"2023-05-21T13:58:26.851669Z","shell.execute_reply.started":"2023-05-21T13:58:26.842732Z","shell.execute_reply":"2023-05-21T13:58:26.850746Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nencoder = encoder model instance\ndecoder = decoder model instance\ndataset = dataset on which to evaluate the model\nbatchsize = number of words in a batch\ncalculates loss and accuracy of the model on the given dataset\n'''\n\ndef evaluatetest(encoder,decoder,dataset,batchsize):\n    loss_total = 0\n    accu_total = 0\n    input_batch = []\n    target_batch = []\n    encoder.eval()\n    decoder.eval()\n    criterion = nn.CrossEntropyLoss()\n    result = []\n    english_words = list(dataset['X'])\n    hindi_words = list(dataset['y'])\n    imax = 30\n\n    for i in range(len(english_words_test)):\n        for j in range(imax - len(english_words_test[i])):\n            english_words_test[i] = english_words_test[i] + '-'\n    input_tensor = [tensorFromWord(lang_input,word) for word in english_words_test]\n    output_tensor = [tensorFromWord(lang_output,word) for word in hindi_words_test]\n\n    \n    \n    for i in range(0,len(english_words),batchsize):\n        if i + batchsize > len(english_words):\n            break\n        input_batch.append(nn.utils.rnn.pad_sequence(input_tensor[i:i + batchsize]).squeeze(2).to(device)) #maxlength,batchsize,1\n        target_batch.append(nn.utils.rnn.pad_sequence(output_tensor[i:i + batchsize]).squeeze(2).to(device)) #maxlength,batch\n    \n    \n    loss = 0\n    for batchnum in range(len(input_batch)):\n        hidden = encoder.initHidden()\n        cell = hidden\n        encoder_hidden = (hidden, cell)\n    \n        input_length = input_batch[batchnum].size(0)\n        target_length = target_batch[batchnum].size(0)\n    \n        encoder_output, encoder_hidden = encoder(\n            input_batch[batchnum], encoder_hidden)\n        decoder_input = torch.tensor([SOW_token] * batchsize, device=device)\n\n        \n        \n        d_hidden = torch.zeros(decoder.num_layers, decoder.batchsize, decoder.hidden_size, device = device)\n        d_cell = torch.zeros(decoder.num_layers, decoder.batchsize, decoder.hidden_size, device = device)\n        (hidden, cell) = encoder_hidden \n        if encoder.num_layers != decoder.num_layers:\n            d_hidden[:,:,:] = hidden[encoder.num_layers - 1,:,:]\n            if cell != None:\n                d_cell[:,:,:] = cell[encoder.num_layers - 1,:,:]\n            else :\n                d_cell = cell\n        else :\n            d_hidden = hidden\n            d_cell = cell\n        if d_cell == None and decoder.modelname == 'LSTM':\n            d_cell = d_hidden\n        decoder_hidden = (d_hidden , d_cell)\n\n        decoder_words = []\n        res_words = []\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden,attn_weights = decoder(\n                decoder_input, decoder_hidden,encoder_output)\n            loss += criterion(decoder_output, target_batch[batchnum][di])\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n            decoder_words.append(topi.squeeze().detach().view(1,-1))\n            res_words.append(topi.squeeze().detach().view(-1,1))\n    #       decoder_words.append([lang_output.index2char[decoder_output[i]] for i in decoder_output.size()[0])\n        accu = accuracy(decoder_words,target_batch[batchnum])\n    \n        loss = loss.item() / target_length\n        loss_total += loss * batchsize\n        accu_total += accu\n\n        for i in range(batchsize):\n            resultantlist = []\n            for j in range(target_length):\n                if res_words[j][i].item() == 1:\n                    break\n                resultantlist.append(lang_output.index2char[res_words[j][i].item()])\n            result.append(resultantlist)\n    loss_total = loss_total/len(english_words)\n    accu_total = (accu_total * 100)/(len(input_batch) * batchsize)\n    print(\"loss = \", loss_total)\n    print('accuracy = ', accu_total)\n    finalresult = []\n    for i in range(len(result)):\n        finalresult.append(''.join(result[i]))\n\n    correct = 0\n    mydict = {}\n    for i in range(len(finalresult)):\n        if finalresult[i] == dataset['y'][i]:\n            correct += 1\n        elif len(dataset['y'][i]) not in mydict:\n            mydict[len(dataset['y'][i])] = 1\n        else:\n            mydict[len(dataset['y'][i])] += 1\n    print('words printed correclty - ' , correct)\n\n    keys = list(mydict.keys())\n    length = [x for x in keys]\n#     print(keys)\n    error = [mydict[x] for x in keys]\n    plt.scatter(length,error)\n    plt.xlabel('length')\n    plt.ylabel('error')\n    plt.show()\n    \n    with open('output.txt' , 'w') as fp:\n        fp.write(\"correct output    \")\n        fp.write(\"predicted output\\n\")\n        fp.write(\"--------------------------------------------\\n\")\n        for i in range(len(finalresult)):\n            fp.write(\"--------------------------------------------\\n\")\n            fp.write(f\"{dataset['y'][i]:<40}{finalresult[i]:<50}\")\n            fp.write('\\n')\n            fp.write(\"--------------------------------------------\\n\")\n    fp.close()\n    \n    \n    vowelerror = 0\n    consonanterror = 0\n    vowelcorrect = 0\n    consonantcorrect = 0\n    actualvowel = 0\n    actualconsonant = 0\n    for i in range(len(result)):\n        truelist = list(dataset['y'][i])\n        for j in range(min(len(truelist) , len(result[i]))):\n            if is_vowel(truelist[j] , lang):\n                actualvowel += 1\n            elif is_consonant(truelist[j] , lang):\n                actualconsonant += 1\n            if is_vowel(truelist[j] , lang):\n                if  truelist[j] != result[i][j]:\n                    vowelerror += 1\n                else:\n                    vowelcorrect += 1\n            elif is_consonant(truelist[j] , lang):\n                if  truelist[j] != result[i][j]:\n                    consonanterror += 1\n                else:\n                    consonantcorrect += 1\n        if len(truelist) > len(result[i]):\n            for j in range(len(result[i]) , len(truelist)):\n                if is_vowel(truelist[j] , lang):\n                    actualvowel += 1\n                elif is_consonant(truelist[j] , lang):\n                    actualconsonant += 1\n                if is_vowel(truelist[j] ,lang):\n                    vowelerror += 1\n                else:\n                    consonanterror += 1\n    \n    \n    print('vowel error = ',vowelerror)\n    print('correct vowel = ' , vowelcorrect)\n    print('consonant error' , consonanterror)\n    print('consonant correct' , consonantcorrect)\n    \n    \n    from sklearn import metrics\n    actual = []\n    predicted = []\n    for i in range(vowelcorrect):\n        actual.append('Vowel')\n        predicted.append('Vowel')\n    for i in range(consonantcorrect):\n        actual.append('Consonant')\n        predicted.append('Consonant')\n    for i in range(vowelerror):\n        actual.append('Vowel')\n        predicted.append('Consonant')\n    for i in range(consonanterror):\n        actual.append('Consonant')\n        predicted.append('Vowel')\n    confusion_matrix = metrics.confusion_matrix(actual, predicted)\n\n    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Consonant', 'Vowel'])\n\n    cm_display.plot()\n    plt.show()\n    \n    print('error when actual character is consonant but predicted is vowel', consonanterror/actualconsonant)\n    print('error when actual character is vowel but predicted is consonant', vowelerror/actualvowel)\n    \n    \n    encoder.train()\n    decoder.train()\n    return loss_total,accu_total","metadata":{"execution":{"iopub.status.busy":"2023-05-21T15:10:19.620556Z","iopub.execute_input":"2023-05-21T15:10:19.621003Z","iopub.status.idle":"2023-05-21T15:10:19.658875Z","shell.execute_reply.started":"2023-05-21T15:10:19.620971Z","shell.execute_reply":"2023-05-21T15:10:19.657774Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# es_128_nenl_2_ndel_2_hs_1024_lr_0.001_bt_0_o_Adam_bs_128_bi_True_n_iters_40_loss_cross_entropy_emn_LSTM_dmn_LSTM_do_0.6","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best configuration\nembedding_size = 128\nnum_encoder_layers = 2\nnum_decoder_layers = 2\nhidden_size = 1024\nlearning_rate = 0.001\nbeta = 0\noptimizer = 'Adam'\nbatchsize = 128\nbidirectional = True\nn_iters = 40\nloss = 'cross_entropy'\nencodermodelname = 'LSTM'\ndecodermodelname = 'LSTM'\ndrop_out = 0.6","metadata":{"execution":{"iopub.status.busy":"2023-05-21T14:49:25.414990Z","iopub.execute_input":"2023-05-21T14:49:25.415866Z","iopub.status.idle":"2023-05-21T14:49:25.424558Z","shell.execute_reply.started":"2023-05-21T14:49:25.415829Z","shell.execute_reply":"2023-05-21T14:49:25.423381Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"encoder1 = EncoderRNN(lang_input.n_chars,hidden_size ,drop_out,num_encoder_layers,batchsize,embedding_size,bidirectional,encodermodelname).to(device)\ndecoder2 = AttnDecoderRNN(hidden_size, lang_output.n_chars,drop_out,num_decoder_layers,batchsize,embedding_size,decodermodelname).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:15:58.878351Z","iopub.execute_input":"2023-05-21T16:15:58.879073Z","iopub.status.idle":"2023-05-21T16:15:59.362464Z","shell.execute_reply.started":"2023-05-21T16:15:58.879039Z","shell.execute_reply":"2023-05-21T16:15:59.361421Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"trainIters(encoder1,decoder2,n_iters,learning_rate,batchsize,optimizer,beta)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T16:16:05.129389Z","iopub.execute_input":"2023-05-21T16:16:05.130406Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"4.22202345904182 0\n","output_type":"stream"}]},{"cell_type":"code","source":"evaluatetest(encoder1,decoder2,df_test,batchsize)","metadata":{"execution":{"iopub.status.busy":"2023-05-21T15:38:00.891183Z","iopub.execute_input":"2023-05-21T15:38:00.892199Z","iopub.status.idle":"2023-05-21T15:38:07.840315Z","shell.execute_reply.started":"2023-05-21T15:38:00.892157Z","shell.execute_reply":"2023-05-21T15:38:07.839361Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"loss =  0.8692643227051183\naccuracy =  35.9619140625\nwords printed correclty -  1473\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"vowel error =  325\ncorrect vowel =  631\nconsonant error 4233\nconsonant correct 12053\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAk4AAAG0CAYAAADEuKgXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABS+UlEQVR4nO3deXQUVfr/8XeHkD2dBSQhEFlklwCyDEZk+xoJig4IDqJRcYgyyiI76AgYQERBlEUElxHEH6igggoKZEAWIQZBgyxhFWRNYIQkBMja9fsjk9IeRDtUwpL+vDx1jl313KpbfRL6yXNv3bYZhmEgIiIiIn/K42p3QEREROR6ocRJRERExEVKnERERERcpMRJRERExEVKnERERERcpMRJRERExEVKnERERERcpMRJRERExEVKnERERERcpMRJRERExEVKnERERKTMrF+/nnvvvZeIiAhsNhtLly41j+Xn5zNq1CiioqLw9/cnIiKCRx99lOPHjzud4/Tp08TFxWG32wkODiY+Pp7s7GynmB9//JG2bdvi4+NDZGQkkydPvqgvixcvpkGDBvj4+BAVFcWXX35Z4vvxLHELueY4HA6OHz9OYGAgNpvtandHRERKwDAMzp49S0REBB4eZVfPyMnJIS8vz/J5vLy88PHxcTn+3LlzNG3alD59+tC9e3enY+fPn+f7779nzJgxNG3alDNnzjBo0CD++te/smXLFjMuLi6OEydOkJiYSH5+Pn//+9/p27cvCxcuBCArK4tOnToRExPDnDlz2L59O3369CE4OJi+ffsCsGnTJh588EEmTZrEPffcw8KFC+nWrRvff/89jRs3dv0NMOS6d+TIEQPQpk2bNm3X8XbkyJEy+5y4cOGCEV6lQqn0Mzw83Lhw4cJl9QMwlixZ8ocxmzdvNgDj559/NgzDMHbt2mUAxnfffWfGfPXVV4bNZjOOHTtmGIZhvPHGG0ZISIiRm5trxowaNcqoX7+++bpnz55Gly5dnK7VunVr4x//+EeJ7kEVp3IgMDAQgJ+/r4k9QKOvUj61mxR/tbsgUiYK83LYtWCC+W95WcjLyyPtZCE/b62JPfDyPyeyzjqo0eIQ//nPf7Db7eZ+b29vvL29S6OrZGZmYrPZCA4OBiApKYng4GBatmxpxsTExODh4UFycjL33XcfSUlJtGvXDi8vLzMmNjaWl19+mTNnzhASEkJSUhJDhw51ulZsbKzT0KErlDiVA8XDc/YAD0u/ECLXsgperg8NiFyPrsRUi4BAGwGBl38dB0VtIyMjnfY///zzJCQkWOkaUDScOGrUKB588EEzMUtLS6NKlSpOcZ6enoSGhpKWlmbG1KpVyykmLCzMPBYSEkJaWpq577cxxedwlRInERERN1FoOCg0rLUHOHLkyEUVJ6vy8/Pp2bMnhmEwe/Zsy+crK0qcRERE3IQDAweXnzkVt7Xb7U6Jk1XFSdPPP//MmjVrnM4dHh7OyZMnneILCgo4ffo04eHhZkx6erpTTPHrP4spPu4qjeuIiIjIVVOcNO3bt49///vfVKpUyel4dHQ0GRkZbN261dy3Zs0aHA4HrVu3NmPWr19Pfn6+GZOYmEj9+vUJCQkxY1avXu107sTERKKjo0vUXyVOIiIibsJRCv+VVHZ2NikpKaSkpABw8OBBUlJSOHz4MPn5+dx///1s2bKFBQsWUFhYSFpaGmlpaebSCQ0bNqRz58488cQTbN68mY0bNzJgwAB69epFREQEAA899BBeXl7Ex8ezc+dOPvroI6ZPn+40GXzQoEGsWLGCqVOnsnv3bhISEtiyZQsDBgwo0f1oqE5ERMRNFBoGhcblD9VdTtstW7bQsWNH83VxMtO7d28SEhL4/PPPAWjWrJlTu6+//poOHToAsGDBAgYMGMAdd9yBh4cHPXr0YMaMGWZsUFAQq1aton///rRo0YLKlSszduxYcw0ngNtuu42FCxcyevRo/vnPf1K3bl2WLl1asjWcANt/11WQ61hWVhZBQUGc2VtbT9VJudUi4amr3QWRMlGYl8P2uc+RmZlZqvOGfqv4c+LI7mqWlyOIbHCsTPt6rVPFSURExE2U1uRwd6bESURExE04MChU4mSJxnVEREREXKSKk4iIiJvQUJ11SpxERETcxNV4qq680VCdiIiIiItUcRIREXETjv9uVtq7OyVOIiIibqLQ4lN1VtqWF0qcRERE3EShUbRZae/uNMdJRERExEWqOImIiLgJzXGyTomTiIiIm3BgoxCbpfbuTkN1IiIiIi5SxUlERMRNOIyizUp7d6fESURExE0UWhyqs9K2vNBQnYiIiIiLVHESERFxE6o4WafESURExE04DBsOw8JTdRbalhcaqhMRERFxkSpOIiIibkJDddYpcRIREXEThXhQaGGwqbAU+3K9UuIkIiLiJgyLc5wMzXHSHCcRERERV6niJCIi4iY0x8k6JU4iIiJuotDwoNCwMMdJX7mioToRERERV6niJCIi4iYc2HBYqJk4UMlJiZOIiIib0Bwn6zRUJyIiIuIiVZxERETchPXJ4RqqU+IkIiLiJormOFn4kl8N1WmoTkRERMRVqjiJiIi4CYfF76rTU3VKnERERNyG5jhZp8RJRETETTjw0DpOFmmOk4iIiIiLVHESERFxE4WGjULDwgKYFtqWF0qcRERE3EShxcnhhRqq01CdiIiIiKtUcRIREXETDsMDh4Wn6hx6qk6Jk4iIiLvQUJ11GqoTERERcZEqTiIiIm7CgbUn4xyl15XrlhInERERN2F9AUwNVOkdEBEREXGRKk4iIiJuwvp31aneosRJRETETTiw4cDKHCetHK7ESURExE2o4mSd3gERERERF6niJCIi4iasL4CpeosSJxERETfhMGw4rKzjZKFteaHUUURERMRFSpxERETchOO/Q3WXu13OApjr16/n3nvvJSIiApvNxtKlS52OG4bB2LFjqVq1Kr6+vsTExLBv3z6nmNOnTxMXF4fdbic4OJj4+Hiys7OdYn788Ufatm2Lj48PkZGRTJ48+aK+LF68mAYNGuDj40NUVBRffvllie9HiZOIiIibcBgelreSOnfuHE2bNmXWrFm/e3zy5MnMmDGDOXPmkJycjL+/P7GxseTk5JgxcXFx7Ny5k8TERJYtW8b69evp27eveTwrK4tOnTpRo0YNtm7dypQpU0hISOCtt94yYzZt2sSDDz5IfHw8P/zwA926daNbt27s2LGjRPdjMwxDX3V8ncvKyiIoKIgze2tjD1QuLOVTi4SnrnYXRMpEYV4O2+c+R2ZmJna7vUyuUfw58eLmjvgEXP705pzsAv75l68vu682m40lS5bQrVs3oKjaFBERwbBhwxg+fDgAmZmZhIWFMW/ePHr16kVqaiqNGjXiu+++o2XLlgCsWLGCu+++m6NHjxIREcHs2bN57rnnSEtLw8vLC4BnnnmGpUuXsnv3bgAeeOABzp07x7Jly8z+3HrrrTRr1ow5c+a4fA/6lBUREXEThdgsb1CUiP12y83Nvaz+HDx4kLS0NGJiYsx9QUFBtG7dmqSkJACSkpIIDg42kyaAmJgYPDw8SE5ONmPatWtnJk0AsbGx7NmzhzNnzpgxv71OcUzxdVylxElERMRNlNZQXWRkJEFBQeY2adKky+pPWloaAGFhYU77w8LCzGNpaWlUqVLF6binpyehoaFOMb93jt9e41IxxcddpeUIREREpESOHDniNFTn7e19FXtzZSlxEhERcROFYA63XW57ALvdXirzscLDwwFIT0+natWq5v709HSaNWtmxpw8edKpXUFBAadPnzbbh4eHk56e7hRT/PrPYoqPu0pDdSIiIm7iajxV90dq1apFeHg4q1evNvdlZWWRnJxMdHQ0ANHR0WRkZLB161YzZs2aNTgcDlq3bm3GrF+/nvz8fDMmMTGR+vXrExISYsb89jrFMcXXcZUSJxERETdR/CW/VraSys7OJiUlhZSUFKBoQnhKSgqHDx/GZrMxePBgXnjhBT7//HO2b9/Oo48+SkREhPnkXcOGDencuTNPPPEEmzdvZuPGjQwYMIBevXoREREBwEMPPYSXlxfx8fHs3LmTjz76iOnTpzN06FCzH4MGDWLFihVMnTqV3bt3k5CQwJYtWxgwYECJ7kdDdSIiIlJmtmzZQseOHc3XxclM7969mTdvHiNHjuTcuXP07duXjIwMbr/9dlasWIGPj4/ZZsGCBQwYMIA77rgDDw8PevTowYwZM8zjQUFBrFq1iv79+9OiRQsqV67M2LFjndZ6uu2221i4cCGjR4/mn//8J3Xr1mXp0qU0bty4RPejdZzKAa3jJO5A6zhJeXUl13F6JukuvAMqXvZ5crPzeSn6qzLt67VOFScRERE3cbnDbb9t7+70DoiIiIi4SBUnERERN+EwbDiMy1+OwErb8kKJk4iIiJsoxINCC4NNVtqWF3oHRERERFykipOIiIib0FCddUqcRERE3IQDDxwWBpustC0v9A6IiIiIuEgVJxERETdRaNgotDDcZqVteaHESURExE1ojpN1SpxERETchGF44LCw+rehlcM1x0lERETEVao4iYiIuIlCbBRiYY6ThbblhRInERERN+EwrM1Tchil2JnrlIbqRERERFykipO4he3f+rP4jSrs2+7H6fSKPP+vg9x2VyYABfkw7+WqfLfGzomfvfC3O7il7Vni/3mcSuEF5jmyzlTgjdHVSE4MwuYBt9+dwVMTjuHr7wAg7YgXvVs3uuja077YS8MW5wH45ssgPpwRxvFD3hTkQ7VaefR48iQx95+5Au+CuKvHbv+BgTHJLPw2iqkr2mD3zeEfHbZw601HCA/KJuO8L2t312T2mlZk53oDEOSbwws9VlM37BeCfHM4fc6XdXtqMmt1a87legHQ7MYTDIz5lpqVM/CpWEBaZiCfbGnIwm+bXs3blT/gsDg53Erb8kKJk7iFnPMe1L75ArEPnmZ8fC2nY7kXPNi/3Y+HBqdTu9EFsjMrMHtsNZ5/rDavr9hrxr08oAan0ysy6cMDFOTbmDr0RqaNiOTZN352Ot9LH+2nRv0c87U95NfkKzC4kAcHpRNZJwfPigbJ/7YzdciNBFcuoGWHs2V09+LOGkWcpHuLXexNq2TuuyHwPDcEnmPaqmgOngqhanA2z96znsqB5xm1qBNQNJyzbndN3ljTijPnfIkMzeSZLt8Q5Lue5z6JAeBCXkUWbW7MvvRKXMj3pNmNaTx3z3ou5FdkydaL/4iQq8+BDYeFeUpW2pYXVz11TEtLY+DAgdSuXRtvb28iIyO59957Wb169dXu2hVns9lYunTp1e5GudTq/87y2Kg02vy3yvRb/nYHL310gPZ/zSCyTi4NW5yn/8Sj7PvRj5NHKwJweJ83W762M2TqYRo0P0/j1ufo98JR1n0WzC9pzn9/2EMKCa1SYG6eFX891vS2bNrclcmNdXOJqJnHfY//h9oNL7Bzs3+Z3r+4J1+vfF7osZoXvmhPVo6Xuf/AyVBGLoplw96aHD0TxHcHq/HG6r/Qrt4hKngUVVDP5njz8ZabST1ehbTMQL47WJ3F391MsxtPmOfZk1aZlTvq8tOpUE5k2Pnqx3okHYjklt/EiJQ3VzVxOnToEC1atGDNmjVMmTKF7du3s2LFCjp27Ej//v2vZtfEzZ3LqoDNZuAfVAhA6hZ/AoIKqNf0ghnTvO1ZbB6w+wfnpOf5x2rRM+pmhnatQ9JK+yWvYRjww4YAjhzwpnHr7LK5EXFrz9y9gW/23sjmn6r/aWyATx7ncr0odPz+x0LlwHN0bPgT3/8ccclz1A//D00i0/4wRq6u4pXDrWzu7qomTv369cNms7F582Z69OhBvXr1uPnmmxk6dCjffvstAIcPH6Zr164EBARgt9vp2bMn6enp5jkSEhJo1qwZ77//PjVr1iQoKIhevXpx9uyvwx4ff/wxUVFR+Pr6UqlSJWJiYjh37hwADoeD8ePHU716dby9vWnWrBkrVqww2x46dAibzcann35Kx44d8fPzo2nTpiQlJZkxv/zyCw8++CDVqlXDz8+PqKgoPvjgA6d77dChA08//TQjR44kNDSU8PBwEhISzOM1a9YE4L777sNms5mv5crLy7Hxr4kRdOh2Bv/Aor++T5/yJLhSgVNcBU8IDC7g9MmiipOvXyF9nz/G6LcOMeH9n7j5L+cY16fWRcnTuSwPutaJokuNpox5tDb9XzhGi/ZKnKR0dWq8nwZV/8Prq1v/aWyw3wUeb7eVT7c2vOjYxB7/ZuNz77By2Pucy/ViwuftL4r5cuj7JI1+i/f7fsLizY1Z+v3F55FrQ/EcJyubu7tq78Dp06dZsWIF/fv3x9//4mGK4OBgHA4HXbt25fTp06xbt47ExER++uknHnjgAafYAwcOsHTpUpYtW8ayZctYt24dL730EgAnTpzgwQcfpE+fPqSmprJ27Vq6d++OYRQ9Uzl9+nSmTp3KK6+8wo8//khsbCx//etf2bdvn9M1nnvuOYYPH05KSgr16tXjwQcfpKCg6IM0JyeHFi1asHz5cnbs2EHfvn155JFH2Lx5s9M53nvvPfz9/UlOTmby5MmMHz+exMREAL777jsA5s6dy4kTJ8zXvyc3N5esrCynTUpHQT5M/EdNMGDgS0dL1DaoUiE9/nGKBs3PU7/ZBeKfO8H/9TjD4tlVnOJ8Axy8kbiHmV/u5bFRJ3hzXDW2bQooxbsQdxdmz2Z454089+kd5BX88VRWf+88pj/0FT+dCuGttS0vOv7qytuIe7MHQz7oTPWQLIbGbroo5vF3u/LIWz2YtKwtD976I7GN910UI1JeXLXJ4fv378cwDBo0aHDJmNWrV7N9+3YOHjxIZGQkAPPnz+fmm2/mu+++o1WrVkBR1WjevHkEBgYC8Mgjj7B69WomTpzIiRMnKCgooHv37tSoUQOAqKgo8xqvvPIKo0aNolevXgC8/PLLfP3110ybNo1Zs2aZccOHD6dLly4AjBs3jptvvpn9+/fToEEDqlWrxvDhw83YgQMHsnLlShYtWsRf/vIXc3+TJk14/vnnAahbty6vv/46q1ev5s477+SGG24AihLG8PDwP3zvJk2axLhx4/4wRkquOGlKP+bF5EX7zWoTQOgNBWT84vzrUlgAZzM8Ca1S8L+nMjW45Tw/rA902ufhUfQ0HcBNjS9wZJ8PH82sQtPbVHWS0tEw4hSVAi6w4B8fm/s8PQya1zhBz7/sIHrCEzgMD/y88pj58HLO5VVk+EexFDgqXHSuX7L9+CXbj0P/CSHrgjf/6vMZ76xrwX+yf/2D93hGUVV1/8lKhAZcoG+HLazcUbfsb1RKzIHF76rT5PCrlzgVV3z+SGpqKpGRkWbSBNCoUSOCg4NJTU01E6eaNWuaSRNA1apVOXnyJABNmzbljjvuICoqitjYWDp16sT9999PSEgIWVlZHD9+nDZt2jhdt02bNmzbts1pX5MmTZzOD3Dy5EkaNGhAYWEhL774IosWLeLYsWPk5eWRm5uLn5/fJc/xv/0siWeffZahQ4ear7OyspzeIym54qTp2EFvJn+8H3toodPxhi3PkZ3pyb4ffanbpGieU8o3gRgOaHDLuUue98BOX0Kr5P/htR0OyM9T+VtKz+afqtHzjZ5O+57v+jWH/hPMextvwWF44O+dx+sPLyev0IOhH3T+08oUgM1W9O92Rc/CS8Z42Ay8/uC4XF2GxafqDCVOVy9xqlu3Ljabjd27d1s+V8WKFZ1e22w2HI6iakGFChVITExk06ZNrFq1ipkzZ/Lcc8+RnJxMpUqVfu90f3oNm63oB6f4GlOmTGH69OlMmzaNqKgo/P39GTx4MHl5eS73syS8vb3x9vYucTt3duGcB8cP/vqepR3x4sAOXwKDCwgNy2fCE7XYv92X8fN/wlFoM+ctBQYXUtHL4Ma6ubTsmMW04ZEMfPkohfk2Zo2uRvuuGeZaT4mLQvCsaHBT46LEauNXQaz6MJTBrxwxr/vhzCrUbXKeiJp55OfZ2LzazupPQhk46QgipeV8nhcHToY67buQ70nmBR8OnAzF3zuPWY8sw6diAWM+jMXfOx9/76IE/8w5HxyGB23q/kyo/wV2Ha/C+TxPbrrhDIM6fUvK4XBO/LfC9LdWO0jLDODQf4IBaF7jBA/fto0Pk6OQa5PDsFhx0uTwq5c4hYaGEhsby6xZs3j66acvmueUkZFBw4YNOXLkCEeOHDErKrt27SIjI4NGjVxfI8Rms9GmTRvatGnD2LFjqVGjBkuWLGHo0KFERESwceNG2rf/dcLjxo0bnYbY/szGjRvp2rUrDz/8MFCUUO3du7dEfYSixKqwUH+plYW92/wYeX8d8/WbCdUAuLPnaR4elsa3q4IA6Hen89Dx5I/3m0Noo17/mVnPVeeZnjeZC2D2e+GYU/zCaeGkH61IBU+IrJPDP+ccou09vy6BkHPeg9f/Gcl/TlTEy8dB5E25jJz5Mx26ZpTFbYv8rgZVTxFVvaja/dkg5wdZ7pn2ECcy7OTme3Jfi1SGdd5ExQqFpGcF8HVqLeZ+c4sZ62EzGBCTTLXgsxQ6PDh6xs7MxFv5RGs4STl2VRfAnDVrFm3atOEvf/kL48ePp0mTJhQUFJCYmMjs2bPZtWsXUVFRxMXFMW3aNAoKCujXrx/t27enZcuLJzH+nuTkZFavXk2nTp2oUqUKycnJnDp1ioYNi576GDFiBM8//zw33XQTzZo1Y+7cuaSkpLBgwQKX76Nu3bp8/PHHbNq0iZCQEF599VXS09NLnDjVrFmT1atX06ZNG7y9vQkJCSlRe7m0prdls/J4yiWP/9GxYvaQwosWu/ytO3ue4c6ef7wC+GOj0nhsVNqfXkuktP1jXlfz/7ceqkaLhCf/MH7LoWr0+dd9fxjz0eYoPtqs6tL1RCuHW3dVE6fatWvz/fffM3HiRIYNG8aJEye44YYbaNGiBbNnz8Zms/HZZ58xcOBA2rVrh4eHB507d2bmzJkuX8Nut7N+/XqmTZtGVlYWNWrUYOrUqdx1110APP3002RmZjJs2DBOnjxJo0aN+Pzzz6lb1/WJjaNHj+ann34iNjYWPz8/+vbtS7du3cjMvHixxT8ydepUhg4dyttvv021atU4dOhQidqLiIj8EQ3VWWczXJmlLde0rKwsgoKCOLO3NvZA/TUg5VOLhKeudhdEykRhXg7b5z5HZmYmdvulF821ovhzouuqPlT09/rzBpeQfy6Pzzq9W6Z9vdbpu+pERETchL6rzjolTiIiIm5CQ3XWaVxHRERExEWqOImIiLgJVZysU+IkIiLiJpQ4WaehOhEREREXqeIkIiLiJlRxsk6Jk4iIiJswsLakgBZ+VOIkIiLiNlRxsk5znERERERcpIqTiIiIm1DFyTolTiIiIm5CiZN1GqoTERERcZEqTiIiIm5CFSfrlDiJiIi4CcOwYVhIfqy0LS80VCciIiLiIlWcRERE3IQDm6UFMK20LS+UOImIiLgJzXGyTkN1IiIiIi5SxUlERMRNaHK4dUqcRERE3ISG6qxT4iQiIuImVHGyTnOcRERERFykipOIiIibMCwO1anipIqTiIiI2zAAw7CwlfB6hYWFjBkzhlq1auHr68tNN93EhAkTMIxfz2QYBmPHjqVq1ar4+voSExPDvn37nM5z+vRp4uLisNvtBAcHEx8fT3Z2tlPMjz/+SNu2bfHx8SEyMpLJkydf5rv0x5Q4iYiISJl4+eWXmT17Nq+//jqpqam8/PLLTJ48mZkzZ5oxkydPZsaMGcyZM4fk5GT8/f2JjY0lJyfHjImLi2Pnzp0kJiaybNky1q9fT9++fc3jWVlZdOrUiRo1arB161amTJlCQkICb731Vqnfk4bqRERE3IQDG7YruHL4pk2b6Nq1K126dAGgZs2afPDBB2zevBkoqjZNmzaN0aNH07VrVwDmz59PWFgYS5cupVevXqSmprJixQq+++47WrZsCcDMmTO5++67eeWVV4iIiGDBggXk5eXx7rvv4uXlxc0330xKSgqvvvqqU4JVGlRxEhERcRPFT9VZ2aCowvPbLTc393evd9ttt7F69Wr27t0LwLZt2/jmm2+46667ADh48CBpaWnExMSYbYKCgmjdujVJSUkAJCUlERwcbCZNADExMXh4eJCcnGzGtGvXDi8vLzMmNjaWPXv2cObMmVJ8B5U4iYiISAlFRkYSFBRkbpMmTfrduGeeeYZevXrRoEEDKlasyC233MLgwYOJi4sDIC0tDYCwsDCndmFhYeaxtLQ0qlSp4nTc09OT0NBQp5jfO8dvr1FaNFQnIiLiJhyGDVspLIB55MgR7Ha7ud/b2/t34xctWsSCBQtYuHChOXw2ePBgIiIi6N2792X342pS4iQiIuImip+Os9IewG63OyVOlzJixAiz6gQQFRXFzz//zKRJk+jduzfh4eEApKenU7VqVbNdeno6zZo1AyA8PJyTJ086nbegoIDTp0+b7cPDw0lPT3eKKX5dHFNaNFQnIiIiZeL8+fN4eDinGhUqVMDhcABQq1YtwsPDWb16tXk8KyuL5ORkoqOjAYiOjiYjI4OtW7eaMWvWrMHhcNC6dWszZv369eTn55sxiYmJ1K9fn5CQkFK9JyVOIiIibqK0Joe76t5772XixIksX76cQ4cOsWTJEl599VXuu+8+AGw2G4MHD+aFF17g888/Z/v27Tz66KNERETQrVs3ABo2bEjnzp154okn2Lx5Mxs3bmTAgAH06tWLiIgIAB566CG8vLyIj49n586dfPTRR0yfPp2hQ4eW6vsHGqoTERFxG1f6u+pmzpzJmDFj6NevHydPniQiIoJ//OMfjB071owZOXIk586do2/fvmRkZHD77bezYsUKfHx8zJgFCxYwYMAA7rjjDjw8POjRowczZswwjwcFBbFq1Sr69+9PixYtqFy5MmPHji31pQgAbIZhZbRTrgVZWVkEBQVxZm9t7IEqIkr51CLhqavdBZEyUZiXw/a5z5GZmenSvKHLUfw5UX/hM1Tw+/2J3K4oPJ/LnodeKtO+Xuv0KSsiIiLiIg3ViYiIuInSeqrOnSlxEhERcRNFiZOVOU6l2JnrlIbqRERERFykipOIiIibuNJP1ZVHSpxERETchPHfzUp7d6ehOhEREREXqeIkIiLiJjRUZ50SJxEREXehsTrLlDiJiIi4C4sVJ1Rx0hwnEREREVep4iQiIuImtHK4dUqcRERE3IQmh1unoToRERERF6niJCIi4i4Mm7UJ3qo4KXESERFxF5rjZJ2G6kRERERcpIqTiIiIu9ACmJa5lDh9/vnnLp/wr3/962V3RkRERMqOnqqzzqXEqVu3bi6dzGazUVhYaKU/IiIiItcslxInh8NR1v0QERGRK0HDbZZYmuOUk5ODj49PafVFREREypCG6qwr8VN1hYWFTJgwgWrVqhEQEMBPP/0EwJgxY/jXv/5V6h0UERGRUmKUwubmSpw4TZw4kXnz5jF58mS8vLzM/Y0bN+add94p1c6JiIiIXEtKnDjNnz+ft956i7i4OCpUqGDub9q0Kbt37y7VzomIiEhpspXC5t5KPMfp2LFj1KlT56L9DoeD/Pz8UumUiIiIlAGt42RZiStOjRo1YsOGDRft//jjj7nllltKpVMiIiIi16ISV5zGjh1L7969OXbsGA6Hg08//ZQ9e/Ywf/58li1bVhZ9FBERkdKgipNlJa44de3alS+++IJ///vf+Pv7M3bsWFJTU/niiy+48847y6KPIiIiUhoMm/XNzV3WOk5t27YlMTGxtPsiIiIick277AUwt2zZQmpqKlA076lFixal1ikREREpfYZRtFlp7+5KnDgdPXqUBx98kI0bNxIcHAxARkYGt912Gx9++CHVq1cv7T6KiIhIadAcJ8tKPMfp8ccfJz8/n9TUVE6fPs3p06dJTU3F4XDw+OOPl0UfRURERK4JJa44rVu3jk2bNlG/fn1zX/369Zk5cyZt27Yt1c6JiIhIKbI6wVuTw0ueOEVGRv7uQpeFhYVERESUSqdERESk9NmMos1Ke3dX4qG6KVOmMHDgQLZs2WLu27JlC4MGDeKVV14p1c6JiIhIKdKX/FrmUsUpJCQEm+3X8ty5c+do3bo1np5FzQsKCvD09KRPnz5069atTDoqIiIicrW5lDhNmzatjLshIiIiZU5znCxzKXHq3bt3WfdDREREypqWI7DsshfABMjJySEvL89pn91ut9QhERERkWtViSeHnzt3jgEDBlClShX8/f0JCQlx2kREROQapcnhlpU4cRo5ciRr1qxh9uzZeHt788477zBu3DgiIiKYP39+WfRRRERESoMSJ8tKPFT3xRdfMH/+fDp06MDf//532rZtS506dahRowYLFiwgLi6uLPopIiIictWVuOJ0+vRpateuDRTNZzp9+jQAt99+O+vXry/d3omIiEjpKX6qzsrm5kqcONWuXZuDBw8C0KBBAxYtWgQUVaKKv/RXRERErj3FK4db2dxdiROnv//972zbtg2AZ555hlmzZuHj48OQIUMYMWJEqXdQRERE5FpR4jlOQ4YMMf8/JiaG3bt3s3XrVurUqUOTJk1KtXMiIiJSirSOk2WW1nECqFGjBjVq1CiNvoiIiIhc01xKnGbMmOHyCZ9++unL7oyIiIiUHRvW5ilpariLidNrr73m0slsNpsSJxERESm3XEqcip+ik2vbffWi8LRVvNrdECkTVXx+uNpdECkTBUbenweVFn3Jr2WW5ziJiIjIdUKTwy0r8XIEIiIiIq46duwYDz/8MJUqVcLX15eoqCi2bNliHjcMg7Fjx1K1alV8fX2JiYlh3759Tuc4ffo0cXFx2O12goODiY+PJzs72ynmxx9/pG3btvj4+BAZGcnkyZPL5H6UOImIiLiLK/xddWfOnKFNmzZUrFiRr776il27djF16lRCQkLMmMmTJzNjxgzmzJlDcnIy/v7+xMbGkpOTY8bExcWxc+dOEhMTWbZsGevXr6dv377m8aysLDp16kSNGjXYunUrU6ZMISEhgbfeeqvEb9Gf0VCdiIiIm7C6+ndJ27788stERkYyd+5cc1+tWrXM/zcMg2nTpjF69Gi6du0KwPz58wkLC2Pp0qX06tWL1NRUVqxYwXfffUfLli0BmDlzJnfffTevvPIKERERLFiwgLy8PN599128vLy4+eabSUlJ4dVXX3VKsEqDKk4iIiJSIllZWU5bbm7u78Z9/vnntGzZkr/97W9UqVKFW265hbfffts8fvDgQdLS0oiJiTH3BQUF0bp1a5KSkgBISkoiODjYTJqgaAFuDw8PkpOTzZh27drh5eVlxsTGxrJnzx7OnDlTqvd+WYnThg0bePjhh4mOjubYsWMAvP/++3zzzTel2jkREREpRaU0VBcZGUlQUJC5TZo06Xcv99NPPzF79mzq1q3LypUreeqpp3j66ad57733AEhLSwMgLCzMqV1YWJh5LC0tjSpVqjgd9/T0JDQ01Cnm987x22uUlhIP1X3yySc88sgjxMXF8cMPP5hZZmZmJi+++CJffvllqXZQRERESkkpPVV35MgR7Ha7udvb2/t3wx0OBy1btuTFF18E4JZbbmHHjh3MmTOH3r17W+jI1VPiitMLL7zAnDlzePvtt6lY8dc1g9q0acP3339fqp0TERGRa4/dbnfaLpU4Va1alUaNGjnta9iwIYcPHwYgPDwcgPT0dKeY9PR081h4eDgnT550Ol5QUMDp06edYn7vHL+9RmkpceK0Z88e2rVrd9H+oKAgMjIySqNPIiIiUgaKJ4db2UqiTZs27Nmzx2nf3r17ze+4rVWrFuHh4axevdo8npWVRXJyMtHR0QBER0eTkZHB1q1bzZg1a9bgcDho3bq1GbN+/Xry8/PNmMTEROrXr+/0BF9pKHHiFB4ezv79+y/a/80331C7du1S6ZSIiIiUgeKVw61sJTBkyBC+/fZbXnzxRfbv38/ChQt566236N+/P1D0VW2DBw/mhRde4PPPP2f79u08+uijRERE0K1bN6CoQtW5c2eeeOIJNm/ezMaNGxkwYAC9evUiIiICgIceeggvLy/i4+PZuXMnH330EdOnT2fo0KGl+vbBZcxxeuKJJxg0aBDvvvsuNpuN48ePk5SUxPDhwxkzZkypd1BERERKyRVeObxVq1YsWbKEZ599lvHjx1OrVi2mTZtGXFycGTNy5EjOnTtH3759ycjI4Pbbb2fFihX4+PiYMQsWLGDAgAHccccdeHh40KNHD2bMmGEeDwoKYtWqVfTv358WLVpQuXJlxo4dW+pLEQDYDMMo0dtgGAYvvvgikyZN4vz580DRpLDhw4czYcKEUu+g/LmsrCyCgoLoQFd9V52UWx6/+UdUpDwpMPJYk7OIzMxMpwnXpan4c6JWwouWfpccOTkcTPhnmfb1WlfiipPNZuO5555jxIgR7N+/n+zsbBo1akRAQEBZ9E9ERERKyZVeALM8uuyVw728vC6aKS8iIiLXMH3Jr2UlTpw6duyIzXbpyWFr1qyx1CERERGRa1WJE6dmzZo5vc7PzyclJYUdO3Zct4tZiYiIuAWLQ3WqOF1G4vTaa6/97v6EhASys7Mtd0hERETKiIbqLCu1L/l9+OGHeffdd0vrdCIiIiLXnMueHP6/kpKSnNZcEBERkWuMKk6WlThx6t69u9NrwzA4ceIEW7Zs0QKYIiIi1zAtR2BdiROnoKAgp9ceHh7Ur1+f8ePH06lTp1LrmIiIiMi1pkSJU2FhIX//+9+Jiooq9S/NExEREbnWlWhyeIUKFejUqRMZGRll1B0REREpM0YpbG6uxE/VNW7cmJ9++qks+iIiIiJlqHiOk5XN3ZU4cXrhhRcYPnw4y5Yt48SJE2RlZTltIiIiIuWVy3Ocxo8fz7Bhw7j77rsB+Otf/+r01SuGYWCz2SgsLCz9XoqIiEjpUNXIEpcTp3HjxvHkk0/y9ddfl2V/REREpKxoHSfLXE6cDKPo3Wrfvn2ZdUZERETkWlai5Qh+OzQnIiIi1xctgGldiRKnevXq/WnydPr0aUsdEhERkTKioTrLSpQ4jRs37qKVw0VERETcRYkSp169elGlSpWy6ouIiIiUIQ3VWedy4qT5TSIiItc5DdVZ5vICmMVP1YmIiIi4K5crTg6Hoyz7ISIiImVNFSfLSjTHSURERK5fmuNknRInERERd6GKk2Ul/pJfEREREXelipOIiIi7UMXJMiVOIiIibkJznKzTUJ2IiIiIi1RxEhERcRcaqrNMiZOIiIib0FCddRqqExEREXGRKk4iIiLuQkN1lilxEhERcRdKnCzTUJ2IiIiIi1RxEhERcRO2/25W2rs7JU4iIiLuQkN1lilxEhERcRNajsA6zXESERERcZEqTiIiIu5CQ3WWKXESERFxJ0p+LNFQnYiIiIiLVHESERFxE5ocbp0SJxEREXehOU6WaahORERExEWqOImIiLgJDdVZp8RJRETEXWiozjIN1YmIiIi4SBUnERERN6GhOuuUOImIiLgLDdVZpsRJRETEXShxskxznERERERcpMRJRETETRTPcbKyWfHSSy9hs9kYPHiwuS8nJ4f+/ftTqVIlAgIC6NGjB+np6U7tDh8+TJcuXfDz86NKlSqMGDGCgoICp5i1a9fSvHlzvL29qVOnDvPmzbPW2UtQ4iQiIuIujFLYLtN3333Hm2++SZMmTZz2DxkyhC+++ILFixezbt06jh8/Tvfu3c3jhYWFdOnShby8PDZt2sR7773HvHnzGDt2rBlz8OBBunTpQseOHUlJSWHw4ME8/vjjrFy58vI7fAlKnERERKRMZWdnExcXx9tvv01ISIi5PzMzk3/961+8+uqr/N///R8tWrRg7ty5bNq0iW+//RaAVatWsWvXLv7f//t/NGvWjLvuuosJEyYwa9Ys8vLyAJgzZw61atVi6tSpNGzYkAEDBnD//ffz2muvlfq9KHESERFxEzbDsLwBZGVlOW25ubl/eN3+/fvTpUsXYmJinPZv3bqV/Px8p/0NGjTgxhtvJCkpCYCkpCSioqIICwszY2JjY8nKymLnzp1mzP+eOzY21jxHaVLiJCIi4i5KaaguMjKSoKAgc5s0adIlL/nhhx/y/fff/25MWloaXl5eBAcHO+0PCwsjLS3NjPlt0lR8vPjYH8VkZWVx4cKFP3xLSkrLEYiIiEiJHDlyBLvdbr729va+ZNygQYNITEzEx8fnSnWvTKniJCIi4iZK66k6u93utF0qcdq6dSsnT56kefPmeHp64unpybp165gxYwaenp6EhYWRl5dHRkaGU7v09HTCw8MBCA8Pv+gpu+LXfxZjt9vx9fW1+rY5UeIkIiLiLq7wU3V33HEH27dvJyUlxdxatmxJXFyc+f8VK1Zk9erVZps9e/Zw+PBhoqOjAYiOjmb79u2cPHnSjElMTMRut9OoUSMz5rfnKI4pPkdp0lCdiIiIlInAwEAaN27stM/f359KlSqZ++Pj4xk6dCihoaHY7XYGDhxIdHQ0t956KwCdOnWiUaNGPPLII0yePJm0tDRGjx5N//79zUrXk08+yeuvv87IkSPp06cPa9asYdGiRSxfvrzU70mJk4iIiJu4Fr/k97XXXsPDw4MePXqQm5tLbGwsb7zxhnm8QoUKLFu2jKeeeoro6Gj8/f3p3bs348ePN2Nq1arF8uXLGTJkCNOnT6d69eq88847xMbGlnp/bYZh6JtnrnNZWVkEBQXRga542ipe7e6IlAmPcjKxVOR/FRh5rMlZRGZmptOE69JU/DnRvNdEKnhd/u9SYV4O33/4XJn29VqnipOIiIibuBYrTtcbTQ4XERERcZEqTiIiIu7C4vfNWWpbTihxEhERcSMabrNGQ3UiIiIiLlLFSURExF0YRtFmpb2bU+IkIiLiJvRUnXUaqhMRERFxkSpOIiIi7kJP1VmmxElERMRN2BxFm5X27k5DdSIiIiIuUsVJBLjn0f/Q5dFfCIvMA+DnPT4seC2MLV/bCQwu4JHhaTRvn02ViDwyT3uyaUUQ700O5/zZCuY5Vh7fdtF5X3zqRtZ9FnLF7kPkUiqF5dFn1GFats/E27eQ4z/78NrI2uzbHgBA3KCjtL/nF26omkd+vo39O/x575VI9mwLMM/Rq98xWnXMoHaj8xTk2/hbs5ZX63bkcmmozjIlTtcYm83GkiVL6Nat29Xuils5daIi775YlWMHvbHZ4M6/nSZh7iH6d6oHNoNKYQW8Pb4qh/f6UKV6Hk+/dJRKYfm80Lem03leGRzJlq8DzdfZWRUQudoC7AVMXbyTbd/aGfP3+mSe9qRazRyyM3/9CDh20Ic3EmqSdtgbLx8H9/VJY+L83cR3bErm6aIvD/f0MtjwVSipPwQQ2/PU1bodsUBP1Vnn1onTvffeS35+PitWrLjo2IYNG2jXrh3btm2jSZMmV6F3ciUlJwY5vZ73clXuefQXGrQ4x8oPKjHhiZrmsRM/ezPv5aqMnHkYjwoGjkKbeSw7qwJnTlW8Ut0WccnfnjzOqRPevDbyJnNf+lEfp5i1n1d2ev32xBvp/MApajU4T8qmot+P/zetOgAxPZQ0Xbe0jpNlbj3HKT4+nsTERI4ePXrRsblz59KyZUslTW7Iw8OgfdczePs5SN3i/7sx/vZCzmd7OCVNAAMmHmXRjh3MWL6XTr1+QXVtuRbcescZ9m3355+v7+ODzVt5/YvtdH7g5CXjPSs6uKvXKbKzKvBTqt8V7KnItc+tE6d77rmHG264gXnz5jntz87OZvHixcTHx/PJJ59w88034+3tTc2aNZk6daoZ9/rrr9O4cWPz9dKlS7HZbMyZM8fcFxMTw+jRo83Xn332Gc2bN8fHx4fatWszbtw4CgoKStTv3NxcsrKynDaxrmaDCyzdt51lh37k6ZeOMj6+Jof3+VwUZw8t4KHB6Xz1/yo57X9vcjgTn6zJs71q882XwQx88Rhd4/9zpbovcknhN+bSJS6dY4d8GP1YA5YvCOPJ5w8R0925cvSX/zvDp9u/47PU7+jW5wTPPdqArDOqoJYnxUN1VjZ359aJk6enJ48++ijz5s3D+E35cfHixRQWFtKwYUN69uxJr1692L59OwkJCYwZM8ZMtNq3b8+uXbs4daroH59169ZRuXJl1q5dC0B+fj5JSUl06NABKBr+e/TRRxk0aBC7du3izTffZN68eUycOLFE/Z40aRJBQUHmFhkZafm9EDh6wJt+d9bj6S51WTa/MsOnH+bGujlOMX4BhUyYf5DDe314f2q407GF08LY9Z0/B3b4sWhWFRbPrsLfntKQhlx9NhvmZO8Du/z56sMqrPiwCnc/5Fx12pZkp/89UQy7vxFb1wfz7Mz9BFXKv0q9ljJhlMLm5tw6cQLo06cPBw4cYN26dea+uXPn0qNHD9566y3uuOMOxowZQ7169XjssccYMGAAU6ZMAaBx48aEhoaabdeuXcuwYcPM15s3byY/P5/bbrsNgHHjxvHMM8/Qu3dvateuzZ133smECRN48803S9TnZ599lszMTHM7cuRIabwVbq8g34Pjh7zZv92PuZOqcnCXL90e/zXx8fUvZOLCn7hwzoNx8TUpLLD9wdlg9/d+3BCRT0UvLXwiV9fpUxU5vN/Xad+RA77cEJHrtC/3QgVO/OzD7pRApj1Tm8JCiO156SE9EXfk9olTgwYNuO2223j33XcB2L9/Pxs2bCA+Pp7U1FTatGnjFN+mTRv27dtHYWEhNpuNdu3asXbtWjIyMti1axf9+vUjNzeX3bt3s27dOlq1aoWfX9EcgW3btjF+/HgCAgLM7YknnuDEiROcP3/e5T57e3tjt9udNil9NhtU9Cr688ovoJAXP/iJ/Dwbzz9Wi/zcP//VuenmC5w9U4H8PLf/NZOrbNfWQKrXdq6eVquVw8lj3n/YzuM3vwNSPmiozjq3fqquWHx8PAMHDmTWrFnMnTuXm266ifbt27vUtkOHDrz11lts2LCBW265BbvdbiZT69atczpPdnY248aNo3v37hedx8fn4rk0cuX8/dkTfLcmkFPHvPANKKTjfRk0uS2b5x6qbSZN3r4OJg+siV9AIX4BhQBk/uKJw2Gj9Z2ZhNxQQOpWP/JzPWje7iy9nj7Jx3NuuMp3JgJL3w1n6uJdPNDvGOuXV6J+02zu6nWSGc/VAsDbt5Be/Y+T/O9gTp/0wh5awL2PpFMpPI8NX4aa57khIpfAoAKqROTi4WFQu+E5AI7/7EPOeS29cV3QU3WWKXECevbsyaBBg1i4cCHz58/nqaeewmaz0bBhQzZu3OgUu3HjRurVq0eFCkX/SLRv357BgwezePFicy5Thw4d+Pe//83GjRsZNmyY2bZ58+bs2bOHOnXqXLF7E9cEVy5gxIzDhFYp4PzZChxM9eG5h2rz/fpAmkRn07BFUUVwXtJup3aP/qUh6Ue9KMy3ce9j/+EfCXnYbHD8kBdvJkTw1YLQ37ucyBW198cAJjxVl8dGHOGhgcdIO+LNmxNq8PVnRUsQOAptRN50gZjupwgKKSArw5O9P/oz4oFGHN7361N1jww+yp33//rAw6zlOwAY+WBDtier8i3uwWYYSh8BHn/8cT799FOysrI4fPgwERERfP/997Rq1YqEhAQeeOABkpKSeOqpp3jjjTd47LHHADAMg8qVK5OZmcmyZcvo3LkzKSkptGzZEpvNRkZGBv7+RY+0r1y5knvuuYfRo0dz//334+HhwbZt29ixYwcvvPACcHkLYGZlZREUFEQHuuJp0xMwUj55qCor5VSBkceanEVkZmaW2dSL4s+J6LvG41nx8n+XCvJzSPpqbJn29VqnyRf/FR8fz5kzZ4iNjSUiIgIoqhAtWrSIDz/8kMaNGzN27FjGjx9vJk1QlOi0bdsWm83G7bffDkCTJk2w2+20bNnSTJoAYmNjWbZsGatWraJVq1bceuutvPbaa9SoUeOK3quIiLgpPVVnmSpO5YAqTuIOVHGS8uqKVpw6l0LFaYV7V5w0x0lERMRN6LvqrFPiJCIi4i4cRtFmpb2bU+IkIiLiLqzOU1LepMnhIiIiIq5SxUlERMRN2LA4x6nUenL9UuIkIiLiLrRyuGUaqhMRERFxkSpOIiIibkLLEVinxElERMRd6Kk6yzRUJyIiIuIiVZxERETchM0wsFmY4G2lbXmhxElERMRdOP67WWnv5jRUJyIiIuIiVZxERETchIbqrFPiJCIi4i70VJ1lSpxERETchVYOt0xznERERERcpIqTiIiIm9DK4dYpcRIREXEXGqqzTEN1IiIiIi5SxUlERMRN2BxFm5X27k6Jk4iIiLvQUJ1lGqoTERERcZEqTiIiIu5CC2BapsRJRETETegrV6zTUJ2IiIiIi1RxEhERcReaHG6ZEicRERF3YQBWlhRQ3qShOhEREXdRPMfJylYSkyZNolWrVgQGBlKlShW6devGnj17nGJycnLo378/lSpVIiAggB49epCenu4Uc/jwYbp06YKfnx9VqlRhxIgRFBQUOMWsXbuW5s2b4+3tTZ06dZg3b95lvUd/RomTiIiIlIl169bRv39/vv32WxITE8nPz6dTp06cO3fOjBkyZAhffPEFixcvZt26dRw/fpzu3bubxwsLC+nSpQt5eXls2rSJ9957j3nz5jF27Fgz5uDBg3Tp0oWOHTuSkpLC4MGDefzxx1m5cmWp35PNMDRgeb3LysoiKCiIDnTF01bxandHpEx4+Phc7S6IlIkCI481OYvIzMzEbreXyTWKPyf+r9kzeFbwvuzzFBTmsiblpcvu66lTp6hSpQrr1q2jXbt2ZGZmcsMNN7Bw4ULuv/9+AHbv3k3Dhg1JSkri1ltv5auvvuKee+7h+PHjhIWFATBnzhxGjRrFqVOn8PLyYtSoUSxfvpwdO3aY1+rVqxcZGRmsWLHisu/396jiJCIi4i6KJ4db2ShKxH675ebmunT5zMxMAEJDQwHYunUr+fn5xMTEmDENGjTgxhtvJCkpCYCkpCSioqLMpAkgNjaWrKwsdu7cacb89hzFMcXnKE1KnERERKREIiMjCQoKMrdJkyb9aRuHw8HgwYNp06YNjRs3BiAtLQ0vLy+Cg4OdYsPCwkhLSzNjfps0FR8vPvZHMVlZWVy4cOGy7vFS9FSdiIiIu3AANovtgSNHjjgN1Xl7//nwX//+/dmxYwfffPONhQ5cfUqcRERE3ERprRxut9tLNMdpwIABLFu2jPXr11O9enVzf3h4OHl5eWRkZDhVndLT0wkPDzdjNm/e7HS+4qfufhvzv0/ipaenY7fb8fX1df0GXaChOhERESkThmEwYMAAlixZwpo1a6hVq5bT8RYtWlCxYkVWr15t7tuzZw+HDx8mOjoagOjoaLZv387JkyfNmMTEROx2O40aNTJjfnuO4pjic5QmVZxERETcxRVeObx///4sXLiQzz77jMDAQHNOUlBQEL6+vgQFBREfH8/QoUMJDQ3FbrczcOBAoqOjufXWWwHo1KkTjRo14pFHHmHy5MmkpaUxevRo+vfvbw4RPvnkk7z++uuMHDmSPn36sGbNGhYtWsTy5csv/14vQYmTiIiIu7jCidPs2bMB6NChg9P+uXPn8thjjwHw2muv4eHhQY8ePcjNzSU2NpY33njDjK1QoQLLli3jqaeeIjo6Gn9/f3r37s348ePNmFq1arF8+XKGDBnC9OnTqV69Ou+88w6xsbGXd59/QOs4lQNax0ncgdZxkvLqSq7jdEej4ZbXcVq965Uy7eu1ThUnERERd6Ev+bVMiZOIiIi7KKXlCNyZEicRERE3UVrLEbgzLUcgIiIi4iJVnERERNyF5jhZpsRJRETEXTgMsFlIfhxKnDRUJyIiIuIiVZxERETchYbqLFPiJCIi4jYsJk4ocdJQnYiIiIiLVHESERFxFxqqs0yJk4iIiLtwGFgabtNTdRqqExEREXGVKk4iIiLuwnAUbVbauzklTiIiIu5Cc5wsU+IkIiLiLjTHyTLNcRIRERFxkSpOIiIi7kJDdZYpcRIREXEXBhYTp1LryXVLQ3UiIiIiLlLFSURExF1oqM4yJU4iIiLuwuEALKzF5NA6ThqqExEREXGRKk4iIiLuQkN1lilxEhERcRdKnCzTUJ2IiIiIi1RxEhERcRf6yhXLlDiJiIi4CcNwYBiX/2SclbblhRInERERd2EY1qpGmuOkOU4iIiIirlLFSURExF0YFuc4qeKkxElERMRtOBxgszBPSXOcNFQnIiIi4ipVnERERNyFhuosU+IkIiLiJgyHA8PCUJ2WI9BQnYiIiIjLVHESERFxFxqqs0yJk4iIiLtwGGBT4mSFhupEREREXKSKk4iIiLswDMDKOk6qOClxEhERcROGw8CwMFRnKHFS4iQiIuI2DAfWKk5ajkBznERERERcpIqTiIiIm9BQnXVKnERERNyFhuosU+JUDhT/BVBAvqV1zUSuZR6GZhZI+VRg5ANXpppj9XOigPzS68x1SolTOXD27FkAvuHLq9wTkTKUc7U7IFK2zp49S1BQUJmc28vLi/DwcL5Js/45ER4ejpeXVyn06vpkMzRged1zOBwcP36cwMBAbDbb1e5OuZeVlUVkZCRHjhzBbrdf7e6IlDr9jF9ZhmFw9uxZIiIi8PAou8pqTk4OeXl5ls/j5eWFj49PKfTo+qSKUzng4eFB9erVr3Y33I7dbteHipRr+hm/csqq0vRbPj4+bp3wlBZNGhARERFxkRInERERERcpcRIpIW9vb55//nm8vb2vdldEyoR+xkUuTZPDRURERFykipOIiIiIi5Q4iYiIiLhIiZOIiIiIi5Q4iYhImbDZbCxduvRqd0OkVClxkutKWloaAwcOpHbt2nh7exMZGcm9997L6tWrr3bXrjh9KMlv3XvvvXTu3Pl3j23YsAGbzcaPP/54hXslUv5o5XC5bhw6dIg2bdoQHBzMlClTiIqKIj8/n5UrV9K/f3927959tbsoctXEx8fTo0cPjh49etE3CcydO5eWLVvSpEmTq9Q7kfJDFSe5bvTr1w+bzcbmzZvp0aMH9erV4+abb2bo0KF8++23ABw+fJiuXbsSEBCA3W6nZ8+epKenm+dISEigWbNmvP/++9SsWZOgoCB69eplflEywMcff0xUVBS+vr5UqlSJmJgYzp07BxR9L+D48eOpXr063t7eNGvWjBUrVphtDx06hM1m49NPP6Vjx474+fnRtGlTkpKSzJhffvmFBx98kGrVquHn50dUVBQffPCB07126NCBp59+mpEjRxIaGkp4eDgJCQnm8Zo1awJw3333YbPZzNfivu655x5uuOEG5s2b57Q/OzubxYsXEx8fzyeffMLNN9+Mt7c3NWvWZOrUqWbc66+/TuPGjc3XS5cuxWazMWfOHHNfTEwMo0ePNl9/9tlnNG/eHB8fH2rXrs24ceMoKCgou5sUuRYYIteBX375xbDZbMaLL754yZjCwkKjWbNmxu23325s2bLF+Pbbb40WLVoY7du3N2Oef/55IyAgwOjevbuxfft2Y/369UZ4eLjxz3/+0zAMwzh+/Ljh6elpvPrqq8bBgweNH3/80Zg1a5Zx9uxZwzAM49VXXzXsdrvxwQcfGLt37zZGjhxpVKxY0di7d69hGIZx8OBBAzAaNGhgLFu2zNizZ49x//33GzVq1DDy8/MNwzCMo0ePGlOmTDF++OEH48CBA8aMGTOMChUqGMnJyWY/27dvb9jtdiMhIcHYu3ev8d577xk2m81YtWqVYRiGcfLkSQMw5s6da5w4ccI4efJkqb7fcn0aMWKEcdNNNxkOh8Pc9+677xq+vr7G2rVrDQ8PD2P8+PHGnj17jLlz5xq+vr7G3LlzDcMwjB9//NGw2Wzmz9LgwYONypUrGw888IBhGIaRl5dn+Pn5GYmJiYZhGMb69esNu91uzJs3zzhw4ICxatUqo2bNmkZCQoJ5bcBYsmTJlbl5kStEiZNcF5KTkw3A+PTTTy8Zs2rVKqNChQrG4cOHzX07d+40AGPz5s2GYRQlTn5+fkZWVpYZM2LECKN169aGYRjG1q1bDcA4dOjQ714jIiLCmDhxotO+Vq1aGf369TMM49fE6Z133rmoD6mpqZfse5cuXYxhw4aZr9u3b2/cfvvtF11n1KhR5mt9KMn/Sk1NNQDj66+/Nve1bdvWePjhh42HHnrIuPPOO53iR4wYYTRq1MgwDMNwOBxGpUqVjMWLFxuGYRjNmjUzJk2aZISHhxuGYRjffPONUbFiRePcuXOGYRjGHXfccdEfMu+//75RtWpV87V+RqU80lCdXBcMFxa4T01NJTIyksjISHNfo0aNCA4OJjU11dxXs2ZNAgMDzddVq1bl5MmTADRt2pQ77riDqKgo/va3v/H2229z5swZALKysjh+/Dht2rRxum6bNm2czg84zSWpWrUqgHmNwsJCJkyYQFRUFKGhoQQEBLBy5UoOHz58yXP8bz9Ffk+DBg247bbbePfddwHYv38/GzZsID4+ntTU1N/92d23bx+FhYXYbDbatWvH2rVrycjIYNeuXfTr14/c3Fx2797NunXraNWqFX5+fgBs27aN8ePHExAQYG5PPPEEJ06c4Pz581f83kWuFCVOcl2oW7cuNputVCaAV6xY0em1zWbD4XAAUKFCBRITE/nqq69o1KgRM2fOpH79+hw8ePCyr2Gz2QDMa0yZMoXp06czatQovv76a1JSUoiNjSUvL8/lfopcSvFcprNnzzJ37lxuuukm2rdv71LbDh06sHbtWjZs2MAtt9yC3W43k6l169Y5nSc7O5tx48aRkpJibtu3b2ffvn34+PiU1e2JXHVKnOS6EBoaSmxsLLNmzTInav9WRkYGDRs25MiRIxw5csTcv2vXLjIyMmjUqJHL17LZbLRp04Zx48bxww8/4OXlxZIlS7Db7URERLBx40an+I0bN5bo/Bs3bqRr1648/PDDNG3alNq1a7N3716X2xerWLEihYWFJW4n5VvPnj3x8PBg4cKFzJ8/nz59+mCz2WjYsOHv/uzWq1ePChUqANC+fXt27drF4sWL6dChA1CUTP373/9m48aN5j6A5s2bs2fPHurUqXPR5uGhjxYpv7QcgVw3Zs2aRZs2bfjLX/7C+PHjadKkCQUFBSQmJjJ79mx27dpFVFQUcXFxTJs2jYKCAvr160f79u1p2bKlS9dITk5m9erVdOrUiSpVqpCcnMypU6do2LAhACNGjOD555/npptuolmzZsydO5eUlBQWLFjg8n3UrVuXjz/+mE2bNhESEsKrr75Kenp6iZIvKBpyXL16NW3atMHb25uQkJAStZfyKSAggAceeIBnn32WrKwsHnvsMQCGDRtGq1atmDBhAg888ABJSUm8/vrrvPHGG2bbJk2aEBISwsKFC1m2bBlQlDgNHz7c/IOi2NixY7nnnnu48cYbuf/++/Hw8GDbtm3s2LGDF1544Yres8iVpD8L5LpRu3Ztvv/+ezp27MiwYcNo3Lgxd955J6tXr2b27NnYbDY+++wzQkJCaNeuHTExMdSuXZuPPvrI5WvY7XbWr1/P3XffTb169Rg9ejRTp07lrrvuAuDpp59m6NChDBs2jKioKFasWMHnn39O3bp1Xb7G6NGjad68ObGxsXTo0IHw8HC6detW0reDqVOnkpiYSGRkJLfcckuJ20v5FR8fz5kzZ4iNjSUiIgIoqhAtWrSIDz/8kMaNGzN27FjGjx9vJlZQVG1t27YtNpuN22+/HShKpux2Oy1btsTf39+MjY2NZdmyZaxatYpWrVpx66238tprr1GjRo0req8iV5rNcGXWrYiIiIio4iQiIiLiKiVOIiIiIi5S4iQiIiLiIiVOIiIiIi5S4iQiIiLiIiVOIiIiIi5S4iQiIiLiIiVOIiIiIi5S4iQipeKxxx5zWgG9Q4cODB48+Ir3Y+3atdhsNjIyMi4ZY7PZWLp0qcvnTEhIoFmzZpb6dejQIWw2GykpKZbOIyJXlxInkXLssccew2azYbPZ8PLyok6dOowfP56CgoIyv/ann37KhAkTXIp1JdkREbkW6Et+Rcq5zp07M3fuXHJzc/nyyy/p378/FStW5Nlnn70oNi8vDy8vr1K5bmhoaKmcR0TkWqKKk0g55+3tTXh4ODVq1OCpp54iJiaGzz//HPh1eG3ixIlERERQv359AI4cOULPnj0JDg4mNDSUrl27cujQIfOchYWFDB06lODgYCpVqsTIkSP536+9/N+hutzcXEaNGkVkZCTe3t7UqVOHf/3rXxw6dIiOHTsCEBISgs1mM7941uFwMGnSJGrVqoWvry9Nmzbl448/drrOl19+Sb169fD19aVjx45O/XTVqFGjqFevHn5+ftSuXZsxY8aQn59/Udybb75JZGQkfn5+9OzZk8zMTKfj77zzDg0bNsTHx4cGDRrwxhtvlLgvInJtU+Ik4mZ8fX3Jy8szX69evZo9e/aQmJjIsmXLyM/PJzY2lsDAQDZs2MDGjRsJCAigc+fOZrupU6cyb9483n33Xb755htOnz7NkiVL/vC6jz76KB988AEzZswgNTWVN998k4CAACIjI/nkk08A2LNnDydOnGD69OkATJo0ifnz5zNnzhx27tzJkCFDePjhh1m3bh1QlOB1796de++9l5SUFB5//HGeeeaZEr8ngYGBzJs3j127djF9+nTefvttXnvtNaeY/fv3s2jRIr744gtWrFjBDz/8QL9+/czjCxYsYOzYsUycOJHU1FRefPFFxowZw3vvvVfi/ojINcwQkXKrd+/eRteuXQ3DMAyHw2EkJiYa3t7exvDhw83jYWFhRm5urtnm/fffN+rXr284HA5zX25uruHr62usXLnSMAzDqFq1qjF58mTzeH5+vlG9enXzWoZhGO3btzcGDRpkGIZh7NmzxwCMxMTE3+3n119/bQDGmTNnzH05OTmGn5+fsWnTJqfY+Ph448EHHzQMwzCeffZZo1GjRk7HR40addG5/hdgLFmy5JLHp0yZYrRo0cJ8/fzzzxsVKlQwjh49au776quvDA8PD+PEiROGYRjGTTfdZCxcuNDpPBMmTDCio6MNwzCMgwcPGoDxww8/XPK6InLt0xwnkXJu2bJlBAQEkJ+fj8Ph4KGHHiIhIcE8HhUV5TSvadu2bezfv5/AwECn8+Tk5HDgwAEyMzM5ceIErVu3No95enrSsmXLi4briqWkpFChQgXat2/vcr/379/P+fPnufPOO5325+XlccsttwCQmprq1A+A6Ohol69R7KOPPmLGjBkcOHCA7OxsCgoKsNvtTjE33ngj1apVc7qOw+Fgz549BAYGcuDAAeLj43niiSfMmIKCAoKCgkrcHxG5dilxEinnOnbsyOzZs/Hy8iIiIgJPT+dfe39/f6fX2dnZtGjRggULFlx0rhtuuOGy+uDr61viNtnZ2QAsX77cKWGBonlbpSUpKYm4uDjGjRtHbGwsQUFBfPjhh0ydOrXEfX377bcvSuQqVKhQan0VkatPiZNIOefv70+dOnVcjm/evDkfffQRVapUuajqUqxq1aokJyfTrl07oKiysnXrVpo3b/678VFRUTgcDtatW0dMTMxFx4srXoWFhea+Ro0a4e3tzeHDhy9ZqWrYsKE50b3Yt99+++c3+RubNm2iRo0aPPfcc+a+n3/++aK4w4cPc/z4cSIiIszreHh4UL9+fcLCwoiIiOCnn34iLi6uRNcXkeuLJoeLiJO4uDgqV65M165d2bBhAwcPHmTt2rU8/fTTHD16FIBBgwbx0ksvsXTpUnbv3k2/fv3+cA2mmjVr0rt3b/r06cPSpUvNcy5atAiAGjVqYLPZWLZsGadOnSI7O5vAwECGDx/OkCFDeO+99zhw4ADff/89M2fONCdcP/nkk+zbt48RI0awZ88eFi5cyLx580p0v3Xr1uXw4cN8+OGHHDhwgBkzZvzuRHcfHx969+7Ntm3b2LBhA08//TQ9e/YkPDwcgHHjxjFp0iRmzJjB3r172b59O3PnzuXVV18tUX9E5NqmxElEnPj5+bF+/XpuvPFGunfvTsOGDYmPjycnJ8esQA0bNoxHHnmE3r17Ex0dTWBgIPfdd98fnnf27Nncf//99OvXjwYNGvDEE09w7tw5AKpVq8a4ceN45plnCAsLY8CAAQBMmDCBMWPGMGnSJBo2bEjnzp1Zvnw5tWrVAormHX3yyScsXbqUpk2bMmfOHF588cUS3e9f//pXhgwZwoABA2jWrBmbNm1izJgxF8XVqVOH7t27c/fdd9OpUyeaNGnitNzA448/zjvvvMPcuXOJioqiffv2zJs3z+yriJQPNuNSszlFRERExIkqTiIiIiIuUuIkIiIi4iIlTiIiIiIuUuIkIiIi4iIlTiIiIiIuUuIkIiIi4iIlTiIiIiIuUuIkIiIi4iIlTiIiIiIuUuIkIiIi4iIlTiIiIiIu+v/8qUSYpaxczQAAAABJRU5ErkJggg=="},"metadata":{}},{"name":"stdout","text":"error when actual character is consonant but predicted is vowel 0.26797923524943024\nerror when actual character is vowel but predicted is consonant 0.3399581589958159\n","output_type":"stream"},{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"(0.8692643227051183, 35.9619140625)"},"metadata":{}}]},{"cell_type":"code","source":"def heatmap(encoder,decoder,dataset,batchsize):\n    loss_total = 0\n    accu_total = 0\n    input_batch = []\n    target_batch = []\n    encoder.eval()\n    decoder.eval()\n    criterion = nn.CrossEntropyLoss()\n    attn_wtlist = []\n    english_words = list(dataset['X'])\n    hindi_words = list(dataset['y'])\n\n    imax = 30\n\n    for i in range(len(english_words_test)):\n        for j in range(imax - len(english_words_test[i])):\n            english_words_test[i] = english_words_test[i] + '-'\n    input_tensor = [tensorFromWord(lang_input,word) for word in english_words_test]\n    output_tensor = [tensorFromWord(lang_output,word) for word in hindi_words_test]\n\n    \n    \n    for i in range(0,len(english_words),batchsize):\n        if i + batchsize > len(english_words):\n            break\n        input_batch.append(nn.utils.rnn.pad_sequence(input_tensor[i:i + batchsize]).squeeze(2).to(device)) #maxlength,batchsize,1\n        target_batch.append(nn.utils.rnn.pad_sequence(output_tensor[i:i + batchsize]).squeeze(2).to(device)) #maxlength,batch\n\n    \n    loss = 0\n    for batchnum in range(len(input_batch)):\n        hidden = encoder.initHidden()\n        cell = hidden\n        encoder_hidden = (hidden, cell)\n    \n        input_length = input_batch[batchnum].size(0)\n        target_length = target_batch[batchnum].size(0)\n    \n        encoder_output, encoder_hidden = encoder(\n            input_batch[batchnum], encoder_hidden)\n        decoder_input = torch.tensor([SOW_token] * batchsize, device=device)\n\n        \n        \n        d_hidden = torch.zeros(decoder.num_layers, decoder.batchsize, decoder.hidden_size, device = device)\n        d_cell = torch.zeros(decoder.num_layers, decoder.batchsize, decoder.hidden_size, device = device)\n        (hidden, cell) = encoder_hidden \n        if encoder.num_layers != decoder.num_layers:\n            d_hidden[:,:,:] = hidden[encoder.num_layers - 1,:,:]\n            if cell != None:\n                d_cell[:,:,:] = cell[encoder.num_layers - 1,:,:]\n            else :\n                d_cell = cell\n        else :\n            d_hidden = hidden\n            d_cell = cell\n        if d_cell == None and decoder.modelname == 'LSTM':\n            d_cell = d_hidden\n        decoder_hidden = (d_hidden , d_cell)\n\n        decoder_words = []\n        for di in range(target_length):\n            decoder_output, decoder_hidden,attn_weights = decoder(\n                decoder_input, decoder_hidden,encoder_output)\n            if batchnum == 0:\n                attn_wtlist.append(attn_weights)\n            loss += criterion(decoder_output, target_batch[batchnum][di])\n            topv, topi = decoder_output.topk(1)\n\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n            decoder_words.append(topi.squeeze().detach().view(1,-1))\n\n        accu = accuracy(decoder_words,target_batch[batchnum])\n    \n        loss = loss.item() / target_length\n        loss_total += loss * batchsize\n        accu_total += accu\n    loss_total = loss_total/len(english_words)\n    accu_total = (accu_total * 100)/(len(input_batch) * batchsize)\n    encoder.train()\n    decoder.train()\n    \n    attn_wtlist = torch.stack(attn_wtlist)\n    \n    attn_wtlist = torch.permute(attn_wtlist,(1,2,0))\n    attn_wtlist = attn_wtlist[:9,:,:].cpu().detach().numpy()\n    xlabel = list(list(x) for x in df_test['X'][:9])\n    ylabel = list(list(x) for x in df_test['y'][:9])\n    fig,axs = plt.subplots(3,3,figsize = (20,20))\n    for itr in range(0,9):\n        ax = axs[itr // 3, itr % 3]\n        \n        data = attn_wtlist[itr,:len(xlabel[itr]),:len(ylabel[itr])]\n#         print('h',data.shape)\n        hindi_font = fm.FontProperties(fname=\"/kaggle/input/hinfont/Nirmala.ttf\")\n        sns.heatmap(data,cmap='viridis',ax = ax,cbar = True,cbar_kws = {'label':'Value'})\n        rows,cols = data.shape\n#         print(rows ,cols, len(xlabel[itr]))\n#         print\n        ax.set_yticks(np.arange(rows) + 0.5)\n        ax.set_yticklabels(xlabel[itr])\n        ax.set_xticks(np.arange(cols) +0.5)\n        ax.set_xticklabels(ylabel[itr],fontproperties = hindi_font)\n#         print(xlabel[itr])\n        cbar = ax.collections[0].colorbar\n        cbar.set_label('Value')\n        fig.savefig(\"ex.png\")\n        temp = plt.imread(\"ex.png\")\n#         plot.append(temp)\n    plt.tight_layout()\n    plt.show()\n    return loss_total,accu_total\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_configuration = {\n    'method': 'bayes',\n    'name': 'ACCURACY VS EPOCH',\n    'metric': {\n        'goal': 'maximize', \n        'name': 'validation_accuracy'\n        },\n    'parameters': {\n        'embeddingsize' : {'values' : [128,256,512]},\n        'number_of_encoder_layers' : {'values' : [2,3]},\n        'number_of_decoder_layers' : {'values' : [2,3]},\n        'hidden_size' : {'values' : [256]},\n\n        'learning_rate': {'values':[0.001,0.0001]},\n        'beta' : {'values' : [0,0.9]},\n        'optimizer' : {'values' : ['Adam']},\n        \n        'batchsize': {'values': [128,256,512]},\n        'bidirectional' : {'values' : [True,False]},\n        'n_iters': {'values': [15,20,30,40]},\n        'loss' : {'values' : ['cross_entropy']},\n        'encodermodelname' : {'values' : ['GRU','LSTM']},\n        'decodermodelname' : {'values' : ['GRU','LSTM']},\n        'drop_out' : {'values' : [0.2,0.3]}\n       }\n    }","metadata":{"execution":{"iopub.status.busy":"2023-05-21T02:12:29.321115Z","iopub.execute_input":"2023-05-21T02:12:29.321922Z","iopub.status.idle":"2023-05-21T02:12:29.332089Z","shell.execute_reply.started":"2023-05-21T02:12:29.321876Z","shell.execute_reply":"2023-05-21T02:12:29.330326Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def withattention():\n    '''\n    main function which runs sweep\n    '''\n    \n    wandb.init(project = 'Assignment 3')\n    config = wandb.config\n    encoder = EncoderRNN(lang_input.n_chars,config.hidden_size ,config.drop_out,config.number_of_encoder_layers,config.batchsize,config.embeddingsize,config.bidirectional,config.encodermodelname).to(device)\n\n    attndecoder = AttnDecoderRNN(config.hidden_size,lang_output.n_chars ,config.drop_out,config.number_of_decoder_layers,config.batchsize,config.embeddingsize,config.decodermodelname).to(device)\n    run_name = \"es_{}_nenl_{}_ndel_{}_hs_{}_lr_{}_bt_{}_o_{}_bs_{}_bi_{}_n_iters_{}_loss_{}_emn_{}_dmn_{}_do_{}\".format(config.embeddingsize,config.number_of_encoder_layers,config.number_of_decoder_layers,config.hidden_size,config.learning_rate,config.beta,config.optimizer,config.batchsize,config.bidirectional,config.n_iters,config.loss,config.encodermodelname,config.decodermodelname,config.drop_out)\n    print(\"run name - \", run_name)\n    wandb.run.name = run_name\n    trainIters(encoder, attndecoder, config.n_iters, config.learning_rate, config.batchsize,config.optimizer,config.beta)\n    print(\"AFTER TRAINING - \")\n    print(\"validation accuracy\" , evaluate(encoder,attndecoder,df_valid,config.batchsize))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sweep_id = wandb.sweep(sweep = sweep_configuration , project = 'Assignment 3')\n\nwandb.agent(sweep_id , function = withattention , count = 18)","metadata":{},"execution_count":null,"outputs":[]}]}
